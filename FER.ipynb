{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanazgit/FER/blob/main/FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Gabrella/QOT/blob/main/main_Upload.py"
      ],
      "metadata": {
        "id": "ERn_LJEI16nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sByzx98bI4HG",
        "outputId": "609c5012-4d9e-48ad-8983-e3c077a67cad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Github commands**"
      ],
      "metadata": {
        "id": "GTO6g1pNhw2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"sani.enmail@gmail.com\"\n",
        "!git config --global user.name \"sanazgit\""
      ],
      "metadata": {
        "id": "mmp-aIukFz-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/sanazgit/FER.git"
      ],
      "metadata": {
        "id": "08tNJ2knF-il",
        "outputId": "537a5118-b244-4fba-a63d-0e9736f332ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FER'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 74 (delta 25), reused 15 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (74/74), 68.43 KiB | 265.00 KiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FER/"
      ],
      "metadata": {
        "id": "xqeFViWnGIiK",
        "outputId": "378f3493-9667-42ac-e201-3ffb5dbade62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch main_upload.py"
      ],
      "metadata": {
        "id": "KIbr4fKlGKw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add option.py"
      ],
      "metadata": {
        "id": "QDtowGq-J4yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "NM8rg2W0J_go",
        "outputId": "901f5c09-b052-4fb7-ea56-92741b6649c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmain_upload.py\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git log --oneline"
      ],
      "metadata": {
        "id": "S_UQpNTPKEtP",
        "outputId": "06cdf80f-c05f-4dc9-d8ee-815ef728f90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m568a1eb\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/HEAD\u001b[m\u001b[33m)\u001b[m Add files via upload\n",
            "\u001b[33mea002d3\u001b[m Created using Colaboratory\n",
            "\u001b[33me511dee\u001b[m Created using Colaboratory\n",
            "\u001b[33m751ba0e\u001b[m Created using Colaboratory\n",
            "\u001b[33m3424d7c\u001b[m Created using Colaboratory\n",
            "\u001b[33m77cc4eb\u001b[m Created using Colaboratory\n",
            "\u001b[33m172a70c\u001b[m Update README.md\n",
            "\u001b[33ma968d57\u001b[m Update README.md\n",
            "\u001b[33m189cb0d\u001b[m Update README.md\n",
            "\u001b[33mfe3e4aa\u001b[m Update README.md\n",
            "\u001b[33m8307b46\u001b[m Update README.md\n",
            "\u001b[33mb8d18f8\u001b[m Update README.md\n",
            "\u001b[33mad52f99\u001b[m Update README.md\n",
            "\u001b[33m821e242\u001b[m Update README.md\n",
            "\u001b[33m6e22033\u001b[m Created using Colaboratory\n",
            "\u001b[33m195b8f0\u001b[m add option.py\n",
            "\u001b[33m175be72\u001b[m Delete p1.py\n",
            "\u001b[33mffb19fe\u001b[m Delete test directory\n",
            "\u001b[33m46a40a9\u001b[m hhii\n",
            "\u001b[33md61e891\u001b[m ch\n",
            "\u001b[33mfee0a3b\u001b[m new file\n",
            "\u001b[33mdb610ae\u001b[m Created using Colaboratory\n",
            "\u001b[33m50d3ad0\u001b[m Created using Colaboratory\n",
            "\u001b[33m96431d7\u001b[m test\n",
            "\u001b[33m66d513a\u001b[m Initial commit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"add option.py\""
      ],
      "metadata": {
        "id": "W3lLOlccKM3h",
        "outputId": "1044e166-708e-417e-eb74-7022bafbd861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmain_upload.py\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "id": "OjWHUtb3Krcq",
        "outputId": "2d30784f-b75f-4229-f5c5-721139503534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/robert1818118/CFNet.git"
      ],
      "metadata": {
        "id": "llNIx5xJZLYA",
        "outputId": "ae2c2aa5-52f6-4d71-f64b-68cba6d21808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CFNet'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 176 (delta 20), reused 0 (delta 0), pack-reused 110\u001b[K\n",
            "Receiving objects: 100% (176/176), 34.50 KiB | 265.00 KiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Method**"
      ],
      "metadata": {
        "id": "IXmCBgvxhw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/liuhw01/AMP-Net.git"
      ],
      "metadata": {
        "id": "fDA_pkMOe-dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsnooper"
      ],
      "metadata": {
        "id": "tU1aNkSQjYF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload a pathon file with some useful functions\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b1708890-5774-4c79-d6b1-472fa4c01bfc",
        "id": "vO8ThopFMv1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-269ba21c-f49b-4484-a26a-fc4fa96f0aaa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-269ba21c-f49b-4484-a26a-fc4fa96f0aaa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet_v1.py to resnet_v1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./AMP-Net/model')"
      ],
      "metadata": {
        "id": "zirx7OrlfgxN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model_ampnet import ampnet\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from util import *\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import random\n",
        "import numbers\n",
        "import torch.nn.functional as F\n",
        "import resnet_v1 as resnet"
      ],
      "metadata": {
        "id": "B7VgGvVhhREc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“‘**Build Dataset**"
      ],
      "metadata": {
        "id": "kiYuNXfB1oHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Test_FER/Dataset/RAFDB/RAFDB.zip"
      ],
      "metadata": {
        "id": "OrrBnGBqierI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination folders\n",
        "src_folder = './RAFDB/test/'\n",
        "dst_folder = './RAFDB/dataset/' # make dataset fplder into RAFDB\n",
        "\n",
        "# List all files in the source folder\n",
        "files = os.listdir(src_folder)\n",
        "\n",
        "# Loop through each file and move it to the destination folder\n",
        "for file in files:\n",
        "    # Construct full file path\n",
        "    src_path = os.path.join(src_folder, file)\n",
        "    dst_path = os.path.join(dst_folder, file)\n",
        "\n",
        "    # Check if the file is an image (e.g., .jpg, .png)\n",
        "    if file.endswith(('.jpg', '.png', '.jpeg')):\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Images moved successfully!\")\n"
      ],
      "metadata": {
        "id": "g1SSptcOn8Z-",
        "outputId": "8ef8f5d2-1446-442d-9044-112e768092aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images moved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = './RAFDB/dataset/'\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "print(f\"There are {len(image_files)} images in the folder.\")"
      ],
      "metadata": {
        "id": "Q3quVgEePrA5",
        "outputId": "f0d37a17-2051-4425-ad36-b0893ba30985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15339 images in the folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do for dataset AND data_facial\n",
        "\n",
        "# Specify the path to your image folder\n",
        "image_folder = '/content/RAFDB/dataset/'\n",
        "\n",
        "# Iterate over the images in the folder\n",
        "for image_file in os.listdir(image_folder):\n",
        "    # Check if \"_aligned\" is in the image name\n",
        "    if \"_aligned\" in image_file:\n",
        "        # Create the new name by replacing \"_aligned\" with an empty string\n",
        "        new_image_name = image_file.replace(\"_aligned\", \"\")\n",
        "\n",
        "        # Rename the image\n",
        "        os.rename(os.path.join(image_folder, image_file), os.path.join(image_folder, new_image_name))"
      ],
      "metadata": {
        "id": "mEO9iMBbqtLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init():\n",
        "\n",
        "  parser = argparse.ArgumentParser(description=\"PyTorch\")\n",
        "\n",
        "  parser.add_argument('--data', type=str, default='/content/RAFDB/dataset/')\n",
        "  parser.add_argument('--data_label', type=str, default='/content/drive/MyDrive/Test_FER/Dataset/RAFDB/data_label.txt')\n",
        "  parser.add_argument('--land_marks', type=str, default='/content/drive/MyDrive/Test_FER/Dataset/RAFDB/land_marks.npy')\n",
        "  parser.add_argument('--checkpoint_path', type=str, default='/content/drive/MyDrive/Test_FER/checkpoint_cnn/RAFDB/' + time_str +  'model.pth.tar')\n",
        "  parser.add_argument('--best_checkpoint_path', type=str, default='/content/drive/MyDrive/Test_FER/checkpoint_cnn/RAFDB/' +time_str + 'model_best.pth.tar')\n",
        "  parser.add_argument('--log_path', type=str, default='/content/drive/MyDrive/Test_FER/log/RAFDB/') #..save_path in ampnet\n",
        "  parser.add_argument('-j', '--workers', default=2, type=int, metavar='N', help='number of data loading workers') #..num_workers in ampnet\n",
        "  parser.add_argument('--epochs', default=100, type=int, metavar='N', help='number of total epochs to run')\n",
        "  parser.add_argument('--start-epoch', default=0, type=int, metavar='N', help='manual epoch number (useful on restarts)')\n",
        "  parser.add_argument('-b', '--batch-size', default=16, type=int, metavar='N')\n",
        "  parser.add_argument('--lr', '--learning-rate', default=0.01, type=float, metavar='LR', dest='lr')\n",
        "  parser.add_argument('--factor', default=0.1, type=float, metavar='FT')\n",
        "  parser.add_argument('--beta1',default=0.5,type=float,metavar='M', help='hyper-parameter ')\n",
        "  parser.add_argument('--af', '--adjust-freq', default=20, type=int, metavar='N', help='adjust learning rate frequency') #..print_freq in ampnet\n",
        "  parser.add_argument('--momentum', default=0.9, type=float, metavar='M')\n",
        "  parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float, metavar='W', dest='weight_decay')\n",
        "  parser.add_argument('--resume', default=False, type=str, metavar='PATH', help='path to checkpoint')\n",
        "  parser.add_argument('--range', default=5, type=int, metavar='N', help='Intercept radius of AP-Module ')\n",
        "  parser.add_argument('--dataset', type=str, default='RAF')\n",
        "  parser.add_argument('--evaluate_path', type=str, default='' + time_str + 'model.pth.tar')\n",
        "  parser.add_argument('-e', '--evaluate', default=False, action='store_true', help='evaluate model on test set')\n",
        "\n",
        "  args = parser.parse_args(args=[])\n",
        "  return args"
      ],
      "metadata": {
        "id": "tdDg_pYmlS_y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ…**Check New Method**"
      ],
      "metadata": {
        "id": "a2iM6-zB2TOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "time_str = now.strftime(\"[%m-%d]-[%H-%M]-\")"
      ],
      "metadata": {
        "id": "TrSI0kFf8r_R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training time: ' + now.strftime(\"%m-%d %H:%M\"))\n",
        "best_acc = 0\n",
        "\n",
        "args= init()\n",
        "\n",
        "data_root = args.data\n",
        "save_path=args.log_path\n",
        "lr=args.lr\n",
        "momentum=args.momentum\n",
        "weight_decay=args.weight_decay\n",
        "epochs=args.epochs\n",
        "batch_size = args.batch_size\n",
        "\n",
        "data_label =  args.data_label\n",
        "data_facial_path=args.land_marks\n",
        "data_facial= np.load(data_facial_path,allow_pickle=True)\n",
        "\n",
        "# Remove \"_aligned\" from each string in the array\n",
        "for i in range(data_facial.shape[0]):\n",
        "    data_facial[i, 0] = data_facial[i, 0].replace('_aligned', '')\n",
        "\n",
        "if args.dataset=='RAF':\n",
        "  train_label, test_label = choose_data(data_label)\n",
        "else:\n",
        "  train_label, test_label = random_choose_data(data_label)\n",
        "\n",
        "mytransform = transforms.Compose([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                  transforms.RandomGrayscale(p=0.2),\n",
        "                                  transforms.ToTensor()])  # transform [0,255] to [0,1]\n",
        "\n",
        "\n",
        "mytransform1 = transforms.Compose([ transforms.ToTensor()])  # transform [0,255] to [0,1]\n",
        "\n",
        "\n",
        "train_data=myImageFloder(root=data_root, label=train_label, transform=mytransform)\n",
        "test_data=myImageFloder(root=data_root, label=test_label, transform=mytransform1)\n",
        "val_data=myImageFloder(root=data_root, label=test_label, transform=mytransform1)\n",
        "\n",
        "# load\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size= batch_size, shuffle=True, num_workers= args.workers, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size= batch_size, shuffle=True, num_workers=  args.workers, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data,batch_size= batch_size, shuffle=True, num_workers= args.workers, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "1zcukcdwfy7t",
        "outputId": "bf2646a1-add3-4be2-94dc-62299cbaa87a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 09-29 22:08\n",
            "the total image is 12271\n",
            "['anger', 'disgust', 'fear', 'happy', 'neural', 'sad', 'surprise']\n",
            "the total image is 3068\n",
            "['anger', 'disgust', 'fear', 'happy', 'neural', 'sad', 'surprise']\n",
            "the total image is 3068\n",
            "['anger', 'disgust', 'fear', 'happy', 'neural', 'sad', 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n"
      ],
      "metadata": {
        "id": "UZ0oGKrsms7y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = out + identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "A53m9_QemYlP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pose_Information(nn.Module):\n",
        "\n",
        "    def __init__(self, block_b , rect, rect_local):\n",
        "\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "      self._norm_layer = norm_layer\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "      self.bn1 = norm_layer(64)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "      self.layer1 = self._make_layer(block_b, 64, 64, 3)  # 56x56x64\n",
        "      self.layer2 = self._make_layer(block_b, 64, 128, 4, stride=2)  # stride=1;28x28x128\n",
        "\n",
        "      self.fc_out = nn.Linear(64*3*10, 7)  # 10 represents the number of features you've extracted\n",
        "\n",
        "\n",
        "      self.rect = rect\n",
        "      self.rect_local = rect_local\n",
        "\n",
        "    def set_rect(self, rect):\n",
        "      self.rect = rect\n",
        "\n",
        "    def get_rect(self):\n",
        "      return self.rect\n",
        "\n",
        "    def set_rect_local(self, rect_local):\n",
        "        self.rect_local = rect_local\n",
        "\n",
        "    def get_rect_local(self):\n",
        "        return self.rect_local\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes:\n",
        "            downsample = nn.Sequential(conv1x1(inplanes, planes, stride), norm_layer(planes))\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(inplanes, planes))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.maxpool(x)\n",
        "      # 56x56x64\n",
        "      x = self.layer1(x)  # 56x56x64\n",
        "      x = self.layer2(x)  # 28x28x128\n",
        "\n",
        "      #... LP Module\n",
        "\n",
        "      top_left = torch.zeros(x.shape[0], x.shape[1], 14, 14).cuda()\n",
        "      top_right = torch.zeros(x.shape[0], x.shape[1], 14, 14).cuda()\n",
        "      bottom_left = torch.zeros(x.shape[0], x.shape[1], 14, 14).cuda()\n",
        "      bottom_right = torch.zeros(x.shape[0], x.shape[1], 14, 14).cuda()\n",
        "\n",
        "      for i in range(len(x)):\n",
        "            #print(i)\n",
        "            if self.rect[i][2] - self.rect[i][0] == 14 :\n",
        "                top_left[i] = x[i][:, self.rect[i][1]:self.rect[i][3], self.rect[i][0]:self.rect[i][2]].clone()\n",
        "            else:\n",
        "                padding1 = 14 - (self.rect[i][2] - self.rect[i][0])\n",
        "                pad_11 = nn.ZeroPad2d(padding=(padding1, 0, padding1, 0))\n",
        "                top_left_min = x[i][:, self.rect[i][1]:self.rect[i][3], self.rect[i][0]:self.rect[i][2]].clone()\n",
        "                top_left[i] = pad_11(top_left_min)\n",
        "\n",
        "            if self.rect[i][4] - self.rect[i][6] == 14:\n",
        "                top_right[i] = x[i][:, self.rect[i][5]:self.rect[i][7], self.rect[i][6]:self.rect[i][4]].clone()\n",
        "            else:\n",
        "                padding2 = 14 - (self.rect[i][4] - self.rect[i][6])\n",
        "                pad_12 = nn.ZeroPad2d(padding=(0, padding2, padding2, 0))\n",
        "                top_right_min = x[i][:, self.rect[i][5]:self.rect[i][7], self.rect[i][6]:self.rect[i][4]].clone()\n",
        "                top_right[i] = pad_12(top_right_min)\n",
        "\n",
        "            if self.rect[i][10] - self.rect[i][8] == 14:\n",
        "                bottom_left[i] = x[i][:, self.rect[i][11]:self.rect[i][9], self.rect[i][8]:self.rect[i][10]].clone()\n",
        "            else:\n",
        "                padding1 = 14 - (self.rect[i][10] - self.rect[i][8])\n",
        "                pad_21 = nn.ZeroPad2d(padding=(padding1, 0, 0, padding1))\n",
        "                bottom_left_min = x[i][:, self.rect[i][11]:self.rect[i][9], self.rect[i][8]:self.rect[i][10]].clone()\n",
        "\n",
        "                bottom_left[i] = pad_21(bottom_left_min)\n",
        "\n",
        "            if self.rect[i][12] - self.rect[i][14] == 14:\n",
        "                bottom_right[i] = x[i][:, self.rect[i][15]:self.rect[i][13], self.rect[i][14]:self.rect[i][12]].clone()\n",
        "            else:\n",
        "                padding2 = 14 - (self.rect[i][12] - self.rect[i][14])\n",
        "                pad_22 = nn.ZeroPad2d(padding=(0, padding2, 0, padding2))\n",
        "                bottom_right_min = x[i][:, self.rect[i][15]:self.rect[i][13], self.rect[i][14]:self.rect[i][12]].clone()\n",
        "                bottom_right[i] = pad_22(bottom_right_min)\n",
        "\n",
        "      #... AP Module\n",
        "\n",
        "      rang = self.rect_local[0][1] - self.rect_local[0][0]\n",
        "      eye1 = x[:, :, 0:rang, 0:rang].clone()\n",
        "      eye2 = x[:, :, 0:rang, 0:rang].clone()\n",
        "      eye_midd = x[:, :, 0:rang, 0:rang].clone()\n",
        "      mouth1 = x[:, :, 0:rang, 0:rang].clone()\n",
        "      mouth2 = x[:, :, 0:rang, 0:rang].clone()\n",
        "\n",
        "      for i in range(x.shape[0]):\n",
        "          eye1[i] = x[i][:, self.rect_local[i][2]:self.rect_local[i][3], self.rect_local[i][0]:self.rect_local[i][1]]\n",
        "          eye2[i] = x[i][:, self.rect_local[i][6]:self.rect_local[i][7], self.rect_local[i][4]:self.rect_local[i][5]]\n",
        "          eye_midd[i] = x[i][:, self.rect_local[i][10]:self.rect_local[i][11],\n",
        "                        self.rect_local[i][8]:self.rect_local[i][9]]\n",
        "          mouth1[i] = x[i][:, self.rect_local[i][14]:self.rect_local[i][15],\n",
        "                      self.rect_local[i][12]:self.rect_local[i][13]]\n",
        "          mouth2[i] = x[i][:, self.rect_local[i][18]:self.rect_local[i][19],\n",
        "                      self.rect_local[i][16]:self.rect_local[i][17]]\n",
        "\n",
        "      # Concatenate the features\n",
        "      features = [top_left, top_right, bottom_left, bottom_right, eye1, eye2, eye_midd, mouth1, mouth2]\n",
        "      concat_features = torch.cat([f.view(f.size(0), -1) for f in features], dim=1)\n",
        "\n",
        "      # Pass the concatenated features through the fully connected layer\n",
        "      x = self.fc_out(concat_features)\n",
        "\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "OEydUmPwPr8u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args= init()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "###### Create Global model  ##########\n",
        "\n",
        "model_cla = resnet.resnet50()\n",
        "model_cla.fc = nn.Linear(2048, 12666)\n",
        "model_cla = torch.nn.DataParallel(model_cla)\n",
        "model_cla.to(device)\n",
        "# pretrianed on msceleb\n",
        "checkpoint = torch.load('/content/drive/MyDrive/FER/Pre_trained/resnet50_pretrained_on_msceleb.pth.tar')\n",
        "pre_trained_dict = checkpoint['state_dict']\n",
        "model_dict = model_cla.state_dict()\n",
        "for k, v in pre_trained_dict.items():\n",
        "  if k in model_dict:\n",
        "    print(k, v.shape)\n",
        "pretrained_dict = {k: v for k, v in pre_trained_dict.items() if k in model_dict}\n",
        "model_dict.update(pretrained_dict)\n",
        "model_cla.load_state_dict(model_dict)\n",
        "model_cla.module.fc = nn.Linear(64*3, 7).cuda()\n",
        "\n",
        "############ Create Global model #########\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GhN1hET3Ro9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test pose class**"
      ],
      "metadata": {
        "id": "f3-aSQobsTRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_facial"
      ],
      "metadata": {
        "id": "RUGht1Za_04r",
        "outputId": "25d1673a-da73-401b-9de8-556c9aae7dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['train_00001.jpg',\n",
              "        array([[ 60.93242,  72.21198],\n",
              "               [163.59874,  75.99979],\n",
              "               [103.47656, 135.27156],\n",
              "               [ 66.40141, 166.95998],\n",
              "               [154.5625 , 170.33635]], dtype=float32)],\n",
              "       ['train_00002.jpg',\n",
              "        array([[ 59.19595 ,  77.115776],\n",
              "               [149.37122 ,  77.796684],\n",
              "               [ 99.88674 , 108.79394 ],\n",
              "               [ 61.349503, 168.91383 ],\n",
              "               [144.25066 , 173.59944 ]], dtype=float32)],\n",
              "       ['train_00003.jpg',\n",
              "        array([[ 54.2099  ,  83.03565 ],\n",
              "               [154.42102 ,  84.366295],\n",
              "               [ 82.45079 , 108.55625 ],\n",
              "               [ 48.50108 , 162.38469 ],\n",
              "               [138.04144 , 166.66405 ]], dtype=float32)],\n",
              "       ...,\n",
              "       ['test_3066.jpg', array([[ 58.20803,  82.2217 ],\n",
              "                                [157.90434,  79.12177],\n",
              "                                [113.36485, 121.26972],\n",
              "                                [ 64.25465, 170.49788],\n",
              "                                [157.11292, 168.0542 ]], dtype=float32)],\n",
              "       ['test_3067.jpg',\n",
              "        array([[ 64.59043 ,  76.76765 ],\n",
              "               [166.1146  ,  72.51156 ],\n",
              "               [128.35188 , 134.38832 ],\n",
              "               [ 70.497765, 168.50867 ],\n",
              "               [159.85574 , 165.53192 ]], dtype=float32)],\n",
              "       ['test_3068.jpg',\n",
              "        array([[ 68.644585,  73.79926 ],\n",
              "               [172.1516  ,  74.54952 ],\n",
              "               [134.55641 , 127.12181 ],\n",
              "               [ 70.63371 , 176.56857 ],\n",
              "               [149.44713 , 182.78589 ]], dtype=float32)]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_name"
      ],
      "metadata": {
        "id": "L1mrWCXw_stk",
        "outputId": "30e7e410-6a90-4e93-80c5-ae7e9b266c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_00001.jpg',\n",
              " 'train_00002.jpg',\n",
              " 'train_00003.jpg',\n",
              " 'train_00004.jpg',\n",
              " 'train_00005.jpg',\n",
              " 'train_00006.jpg',\n",
              " 'train_00007.jpg',\n",
              " 'train_00008.jpg',\n",
              " 'train_00009.jpg',\n",
              " 'train_00010.jpg',\n",
              " 'train_00011.jpg',\n",
              " 'train_00012.jpg',\n",
              " 'train_00013.jpg',\n",
              " 'train_00014.jpg',\n",
              " 'train_00016.jpg',\n",
              " 'train_00018.jpg',\n",
              " 'train_00019.jpg',\n",
              " 'train_00020.jpg',\n",
              " 'train_00021.jpg',\n",
              " 'train_00022.jpg',\n",
              " 'train_00023.jpg',\n",
              " 'train_00024.jpg',\n",
              " 'train_00025.jpg',\n",
              " 'train_00026.jpg',\n",
              " 'train_00027.jpg',\n",
              " 'train_00028.jpg',\n",
              " 'train_00029.jpg',\n",
              " 'train_00030.jpg',\n",
              " 'train_00031.jpg',\n",
              " 'train_00032.jpg',\n",
              " 'train_00034.jpg',\n",
              " 'train_00035.jpg',\n",
              " 'train_00036.jpg',\n",
              " 'train_00037.jpg',\n",
              " 'train_00038.jpg',\n",
              " 'train_00040.jpg',\n",
              " 'train_00041.jpg',\n",
              " 'train_00042.jpg',\n",
              " 'train_00044.jpg',\n",
              " 'train_00045.jpg',\n",
              " 'train_00046.jpg',\n",
              " 'train_00047.jpg',\n",
              " 'train_00048.jpg',\n",
              " 'train_00049.jpg',\n",
              " 'train_00050.jpg',\n",
              " 'train_00051.jpg',\n",
              " 'train_00052.jpg',\n",
              " 'train_00053.jpg',\n",
              " 'train_00054.jpg',\n",
              " 'train_00055.jpg',\n",
              " 'train_00056.jpg',\n",
              " 'train_00057.jpg',\n",
              " 'train_00058.jpg',\n",
              " 'train_00059.jpg',\n",
              " 'train_00060.jpg',\n",
              " 'train_00061.jpg',\n",
              " 'train_00062.jpg',\n",
              " 'train_00063.jpg',\n",
              " 'train_00064.jpg',\n",
              " 'train_00065.jpg',\n",
              " 'train_00066.jpg',\n",
              " 'train_00067.jpg',\n",
              " 'train_00068.jpg',\n",
              " 'train_00069.jpg',\n",
              " 'train_00070.jpg',\n",
              " 'train_00071.jpg',\n",
              " 'train_00072.jpg',\n",
              " 'train_00073.jpg',\n",
              " 'train_00074.jpg',\n",
              " 'train_00075.jpg',\n",
              " 'train_00076.jpg',\n",
              " 'train_00077.jpg',\n",
              " 'train_00078.jpg',\n",
              " 'train_00081.jpg',\n",
              " 'train_00082.jpg',\n",
              " 'train_00083.jpg',\n",
              " 'train_00084.jpg',\n",
              " 'train_00085.jpg',\n",
              " 'train_00086.jpg',\n",
              " 'train_00087.jpg',\n",
              " 'train_00088.jpg',\n",
              " 'train_00089.jpg',\n",
              " 'train_00090.jpg',\n",
              " 'train_00092.jpg',\n",
              " 'train_00093.jpg',\n",
              " 'train_00094.jpg',\n",
              " 'train_00095.jpg',\n",
              " 'train_00096.jpg',\n",
              " 'train_00097.jpg',\n",
              " 'train_00098.jpg',\n",
              " 'train_00099.jpg',\n",
              " 'train_00100.jpg',\n",
              " 'train_00101.jpg',\n",
              " 'train_00102.jpg',\n",
              " 'train_00103.jpg',\n",
              " 'train_00104.jpg',\n",
              " 'train_00106.jpg',\n",
              " 'train_00107.jpg',\n",
              " 'train_00109.jpg',\n",
              " 'train_00110.jpg',\n",
              " 'train_00111.jpg',\n",
              " 'train_00112.jpg',\n",
              " 'train_00113.jpg',\n",
              " 'train_00114.jpg',\n",
              " 'train_00116.jpg',\n",
              " 'train_00117.jpg',\n",
              " 'train_00118.jpg',\n",
              " 'train_00119.jpg',\n",
              " 'train_00120.jpg',\n",
              " 'train_00121.jpg',\n",
              " 'train_00122.jpg',\n",
              " 'train_00123.jpg',\n",
              " 'train_00124.jpg',\n",
              " 'train_00125.jpg',\n",
              " 'train_00126.jpg',\n",
              " 'train_00129.jpg',\n",
              " 'train_00130.jpg',\n",
              " 'train_00131.jpg',\n",
              " 'train_00132.jpg',\n",
              " 'train_00133.jpg',\n",
              " 'train_00134.jpg',\n",
              " 'train_00135.jpg',\n",
              " 'train_00136.jpg',\n",
              " 'train_00137.jpg',\n",
              " 'train_00138.jpg',\n",
              " 'train_00139.jpg',\n",
              " 'train_00140.jpg',\n",
              " 'train_00141.jpg',\n",
              " 'train_00142.jpg',\n",
              " 'train_00143.jpg',\n",
              " 'train_00144.jpg',\n",
              " 'train_00145.jpg',\n",
              " 'train_00146.jpg',\n",
              " 'train_00147.jpg',\n",
              " 'train_00148.jpg',\n",
              " 'train_00149.jpg',\n",
              " 'train_00150.jpg',\n",
              " 'train_00151.jpg',\n",
              " 'train_00152.jpg',\n",
              " 'train_00153.jpg',\n",
              " 'train_00154.jpg',\n",
              " 'train_00155.jpg',\n",
              " 'train_00156.jpg',\n",
              " 'train_00158.jpg',\n",
              " 'train_00159.jpg',\n",
              " 'train_00160.jpg',\n",
              " 'train_00162.jpg',\n",
              " 'train_00163.jpg',\n",
              " 'train_00165.jpg',\n",
              " 'train_00166.jpg',\n",
              " 'train_00167.jpg',\n",
              " 'train_00168.jpg',\n",
              " 'train_00169.jpg',\n",
              " 'train_00170.jpg',\n",
              " 'train_00171.jpg',\n",
              " 'train_00172.jpg',\n",
              " 'train_00173.jpg',\n",
              " 'train_00174.jpg',\n",
              " 'train_00175.jpg',\n",
              " 'train_00176.jpg',\n",
              " 'train_00177.jpg',\n",
              " 'train_00178.jpg',\n",
              " 'train_00179.jpg',\n",
              " 'train_00181.jpg',\n",
              " 'train_00182.jpg',\n",
              " 'train_00183.jpg',\n",
              " 'train_00184.jpg',\n",
              " 'train_00185.jpg',\n",
              " 'train_00186.jpg',\n",
              " 'train_00187.jpg',\n",
              " 'train_00188.jpg',\n",
              " 'train_00189.jpg',\n",
              " 'train_00190.jpg',\n",
              " 'train_00191.jpg',\n",
              " 'train_00192.jpg',\n",
              " 'train_00193.jpg',\n",
              " 'train_00194.jpg',\n",
              " 'train_00195.jpg',\n",
              " 'train_00196.jpg',\n",
              " 'train_00197.jpg',\n",
              " 'train_00198.jpg',\n",
              " 'train_00199.jpg',\n",
              " 'train_00200.jpg',\n",
              " 'train_00201.jpg',\n",
              " 'train_00202.jpg',\n",
              " 'train_00203.jpg',\n",
              " 'train_00204.jpg',\n",
              " 'train_00205.jpg',\n",
              " 'train_00207.jpg',\n",
              " 'train_00208.jpg',\n",
              " 'train_00209.jpg',\n",
              " 'train_00210.jpg',\n",
              " 'train_00211.jpg',\n",
              " 'train_00212.jpg',\n",
              " 'train_00213.jpg',\n",
              " 'train_00214.jpg',\n",
              " 'train_00215.jpg',\n",
              " 'train_00216.jpg',\n",
              " 'train_00217.jpg',\n",
              " 'train_00218.jpg',\n",
              " 'train_00219.jpg',\n",
              " 'train_00220.jpg',\n",
              " 'train_00221.jpg',\n",
              " 'train_00222.jpg',\n",
              " 'train_00223.jpg',\n",
              " 'train_00224.jpg',\n",
              " 'train_00225.jpg',\n",
              " 'train_00226.jpg',\n",
              " 'train_00227.jpg',\n",
              " 'train_00228.jpg',\n",
              " 'train_00230.jpg',\n",
              " 'train_00231.jpg',\n",
              " 'train_00233.jpg',\n",
              " 'train_00234.jpg',\n",
              " 'train_00235.jpg',\n",
              " 'train_00236.jpg',\n",
              " 'train_00237.jpg',\n",
              " 'train_00238.jpg',\n",
              " 'train_00239.jpg',\n",
              " 'train_00240.jpg',\n",
              " 'train_00241.jpg',\n",
              " 'train_00243.jpg',\n",
              " 'train_00244.jpg',\n",
              " 'train_00245.jpg',\n",
              " 'train_00246.jpg',\n",
              " 'train_00247.jpg',\n",
              " 'train_00248.jpg',\n",
              " 'train_00249.jpg',\n",
              " 'train_00250.jpg',\n",
              " 'train_00251.jpg',\n",
              " 'train_00252.jpg',\n",
              " 'train_00253.jpg',\n",
              " 'train_00254.jpg',\n",
              " 'train_00255.jpg',\n",
              " 'train_00256.jpg',\n",
              " 'train_00257.jpg',\n",
              " 'train_00258.jpg',\n",
              " 'train_00259.jpg',\n",
              " 'train_00260.jpg',\n",
              " 'train_00261.jpg',\n",
              " 'train_00262.jpg',\n",
              " 'train_00264.jpg',\n",
              " 'train_00265.jpg',\n",
              " 'train_00266.jpg',\n",
              " 'train_00267.jpg',\n",
              " 'train_00269.jpg',\n",
              " 'train_00270.jpg',\n",
              " 'train_00271.jpg',\n",
              " 'train_00272.jpg',\n",
              " 'train_00273.jpg',\n",
              " 'train_00274.jpg',\n",
              " 'train_00275.jpg',\n",
              " 'train_00276.jpg',\n",
              " 'train_00277.jpg',\n",
              " 'train_00278.jpg',\n",
              " 'train_00279.jpg',\n",
              " 'train_00280.jpg',\n",
              " 'train_00281.jpg',\n",
              " 'train_00282.jpg',\n",
              " 'train_00284.jpg',\n",
              " 'train_00285.jpg',\n",
              " 'train_00287.jpg',\n",
              " 'train_00290.jpg',\n",
              " 'train_00291.jpg',\n",
              " 'train_00293.jpg',\n",
              " 'train_00294.jpg',\n",
              " 'train_00295.jpg',\n",
              " 'train_00296.jpg',\n",
              " 'train_00297.jpg',\n",
              " 'train_00298.jpg',\n",
              " 'train_00299.jpg',\n",
              " 'train_00300.jpg',\n",
              " 'train_00302.jpg',\n",
              " 'train_00303.jpg',\n",
              " 'train_00304.jpg',\n",
              " 'train_00305.jpg',\n",
              " 'train_00306.jpg',\n",
              " 'train_00307.jpg',\n",
              " 'train_00308.jpg',\n",
              " 'train_00309.jpg',\n",
              " 'train_00310.jpg',\n",
              " 'train_00311.jpg',\n",
              " 'train_00312.jpg',\n",
              " 'train_00313.jpg',\n",
              " 'train_00314.jpg',\n",
              " 'train_00315.jpg',\n",
              " 'train_00317.jpg',\n",
              " 'train_00318.jpg',\n",
              " 'train_00319.jpg',\n",
              " 'train_00320.jpg',\n",
              " 'train_00321.jpg',\n",
              " 'train_00322.jpg',\n",
              " 'train_00323.jpg',\n",
              " 'train_00324.jpg',\n",
              " 'train_00326.jpg',\n",
              " 'train_00327.jpg',\n",
              " 'train_00328.jpg',\n",
              " 'train_00329.jpg',\n",
              " 'train_00330.jpg',\n",
              " 'train_00331.jpg',\n",
              " 'train_00332.jpg',\n",
              " 'train_00333.jpg',\n",
              " 'train_00334.jpg',\n",
              " 'train_00335.jpg',\n",
              " 'train_00336.jpg',\n",
              " 'train_00337.jpg',\n",
              " 'train_00338.jpg',\n",
              " 'train_00340.jpg',\n",
              " 'train_00341.jpg',\n",
              " 'train_00342.jpg',\n",
              " 'train_00343.jpg',\n",
              " 'train_00344.jpg',\n",
              " 'train_00345.jpg',\n",
              " 'train_00346.jpg',\n",
              " 'train_00347.jpg',\n",
              " 'train_00348.jpg',\n",
              " 'train_00349.jpg',\n",
              " 'train_00350.jpg',\n",
              " 'train_00351.jpg',\n",
              " 'train_00352.jpg',\n",
              " 'train_00353.jpg',\n",
              " 'train_00354.jpg',\n",
              " 'train_00355.jpg',\n",
              " 'train_00357.jpg',\n",
              " 'train_00359.jpg',\n",
              " 'train_00360.jpg',\n",
              " 'train_00361.jpg',\n",
              " 'train_00362.jpg',\n",
              " 'train_00363.jpg',\n",
              " 'train_00365.jpg',\n",
              " 'train_00366.jpg',\n",
              " 'train_00367.jpg',\n",
              " 'train_00368.jpg',\n",
              " 'train_00369.jpg',\n",
              " 'train_00370.jpg',\n",
              " 'train_00371.jpg',\n",
              " 'train_00372.jpg',\n",
              " 'train_00374.jpg',\n",
              " 'train_00375.jpg',\n",
              " 'train_00376.jpg',\n",
              " 'train_00377.jpg',\n",
              " 'train_00378.jpg',\n",
              " 'train_00379.jpg',\n",
              " 'train_00380.jpg',\n",
              " 'train_00381.jpg',\n",
              " 'train_00382.jpg',\n",
              " 'train_00383.jpg',\n",
              " 'train_00384.jpg',\n",
              " 'train_00385.jpg',\n",
              " 'train_00387.jpg',\n",
              " 'train_00388.jpg',\n",
              " 'train_00389.jpg',\n",
              " 'train_00390.jpg',\n",
              " 'train_00391.jpg',\n",
              " 'train_00392.jpg',\n",
              " 'train_00393.jpg',\n",
              " 'train_00394.jpg',\n",
              " 'train_00395.jpg',\n",
              " 'train_00396.jpg',\n",
              " 'train_00397.jpg',\n",
              " 'train_00398.jpg',\n",
              " 'train_00399.jpg',\n",
              " 'train_00400.jpg',\n",
              " 'train_00401.jpg',\n",
              " 'train_00402.jpg',\n",
              " 'train_00403.jpg',\n",
              " 'train_00404.jpg',\n",
              " 'train_00405.jpg',\n",
              " 'train_00406.jpg',\n",
              " 'train_00407.jpg',\n",
              " 'train_00408.jpg',\n",
              " 'train_00409.jpg',\n",
              " 'train_00410.jpg',\n",
              " 'train_00411.jpg',\n",
              " 'train_00412.jpg',\n",
              " 'train_00414.jpg',\n",
              " 'train_00415.jpg',\n",
              " 'train_00416.jpg',\n",
              " 'train_00417.jpg',\n",
              " 'train_00418.jpg',\n",
              " 'train_00419.jpg',\n",
              " 'train_00420.jpg',\n",
              " 'train_00421.jpg',\n",
              " 'train_00422.jpg',\n",
              " 'train_00423.jpg',\n",
              " 'train_00424.jpg',\n",
              " 'train_00425.jpg',\n",
              " 'train_00426.jpg',\n",
              " 'train_00427.jpg',\n",
              " 'train_00430.jpg',\n",
              " 'train_00431.jpg',\n",
              " 'train_00432.jpg',\n",
              " 'train_00433.jpg',\n",
              " 'train_00434.jpg',\n",
              " 'train_00435.jpg',\n",
              " 'train_00438.jpg',\n",
              " 'train_00439.jpg',\n",
              " 'train_00440.jpg',\n",
              " 'train_00441.jpg',\n",
              " 'train_00442.jpg',\n",
              " 'train_00443.jpg',\n",
              " 'train_00444.jpg',\n",
              " 'train_00445.jpg',\n",
              " 'train_00446.jpg',\n",
              " 'train_00447.jpg',\n",
              " 'train_00448.jpg',\n",
              " 'train_00449.jpg',\n",
              " 'train_00450.jpg',\n",
              " 'train_00451.jpg',\n",
              " 'train_00453.jpg',\n",
              " 'train_00454.jpg',\n",
              " 'train_00455.jpg',\n",
              " 'train_00456.jpg',\n",
              " 'train_00457.jpg',\n",
              " 'train_00458.jpg',\n",
              " 'train_00459.jpg',\n",
              " 'train_00461.jpg',\n",
              " 'train_00462.jpg',\n",
              " 'train_00463.jpg',\n",
              " 'train_00464.jpg',\n",
              " 'train_00465.jpg',\n",
              " 'train_00466.jpg',\n",
              " 'train_00467.jpg',\n",
              " 'train_00468.jpg',\n",
              " 'train_00469.jpg',\n",
              " 'train_00470.jpg',\n",
              " 'train_00471.jpg',\n",
              " 'train_00472.jpg',\n",
              " 'train_00473.jpg',\n",
              " 'train_00474.jpg',\n",
              " 'train_00475.jpg',\n",
              " 'train_00476.jpg',\n",
              " 'train_00477.jpg',\n",
              " 'train_00478.jpg',\n",
              " 'train_00479.jpg',\n",
              " 'train_00480.jpg',\n",
              " 'train_00481.jpg',\n",
              " 'train_00482.jpg',\n",
              " 'train_00483.jpg',\n",
              " 'train_00484.jpg',\n",
              " 'train_00485.jpg',\n",
              " 'train_00486.jpg',\n",
              " 'train_00487.jpg',\n",
              " 'train_00488.jpg',\n",
              " 'train_00489.jpg',\n",
              " 'train_00490.jpg',\n",
              " 'train_00491.jpg',\n",
              " 'train_00493.jpg',\n",
              " 'train_00494.jpg',\n",
              " 'train_00496.jpg',\n",
              " 'train_00498.jpg',\n",
              " 'train_00499.jpg',\n",
              " 'train_00500.jpg',\n",
              " 'train_00501.jpg',\n",
              " 'train_00502.jpg',\n",
              " 'train_00503.jpg',\n",
              " 'train_00504.jpg',\n",
              " 'train_00505.jpg',\n",
              " 'train_00506.jpg',\n",
              " 'train_00507.jpg',\n",
              " 'train_00508.jpg',\n",
              " 'train_00509.jpg',\n",
              " 'train_00510.jpg',\n",
              " 'train_00512.jpg',\n",
              " 'train_00513.jpg',\n",
              " 'train_00514.jpg',\n",
              " 'train_00516.jpg',\n",
              " 'train_00517.jpg',\n",
              " 'train_00518.jpg',\n",
              " 'train_00519.jpg',\n",
              " 'train_00520.jpg',\n",
              " 'train_00521.jpg',\n",
              " 'train_00522.jpg',\n",
              " 'train_00523.jpg',\n",
              " 'train_00524.jpg',\n",
              " 'train_00525.jpg',\n",
              " 'train_00527.jpg',\n",
              " 'train_00528.jpg',\n",
              " 'train_00529.jpg',\n",
              " 'train_00530.jpg',\n",
              " 'train_00531.jpg',\n",
              " 'train_00532.jpg',\n",
              " 'train_00533.jpg',\n",
              " 'train_00534.jpg',\n",
              " 'train_00535.jpg',\n",
              " 'train_00536.jpg',\n",
              " 'train_00538.jpg',\n",
              " 'train_00539.jpg',\n",
              " 'train_00540.jpg',\n",
              " 'train_00541.jpg',\n",
              " 'train_00542.jpg',\n",
              " 'train_00543.jpg',\n",
              " 'train_00544.jpg',\n",
              " 'train_00545.jpg',\n",
              " 'train_00546.jpg',\n",
              " 'train_00547.jpg',\n",
              " 'train_00548.jpg',\n",
              " 'train_00549.jpg',\n",
              " 'train_00550.jpg',\n",
              " 'train_00552.jpg',\n",
              " 'train_00553.jpg',\n",
              " 'train_00555.jpg',\n",
              " 'train_00556.jpg',\n",
              " 'train_00557.jpg',\n",
              " 'train_00558.jpg',\n",
              " 'train_00559.jpg',\n",
              " 'train_00560.jpg',\n",
              " 'train_00561.jpg',\n",
              " 'train_00562.jpg',\n",
              " 'train_00563.jpg',\n",
              " 'train_00564.jpg',\n",
              " 'train_00565.jpg',\n",
              " 'train_00566.jpg',\n",
              " 'train_00567.jpg',\n",
              " 'train_00568.jpg',\n",
              " 'train_00569.jpg',\n",
              " 'train_00570.jpg',\n",
              " 'train_00571.jpg',\n",
              " 'train_00572.jpg',\n",
              " 'train_00573.jpg',\n",
              " 'train_00574.jpg',\n",
              " 'train_00575.jpg',\n",
              " 'train_00576.jpg',\n",
              " 'train_00577.jpg',\n",
              " 'train_00578.jpg',\n",
              " 'train_00579.jpg',\n",
              " 'train_00580.jpg',\n",
              " 'train_00582.jpg',\n",
              " 'train_00583.jpg',\n",
              " 'train_00584.jpg',\n",
              " 'train_00585.jpg',\n",
              " 'train_00587.jpg',\n",
              " 'train_00588.jpg',\n",
              " 'train_00589.jpg',\n",
              " 'train_00590.jpg',\n",
              " 'train_00591.jpg',\n",
              " 'train_00592.jpg',\n",
              " 'train_00594.jpg',\n",
              " 'train_00595.jpg',\n",
              " 'train_00596.jpg',\n",
              " 'train_00597.jpg',\n",
              " 'train_00598.jpg',\n",
              " 'train_00599.jpg',\n",
              " 'train_00600.jpg',\n",
              " 'train_00601.jpg',\n",
              " 'train_00602.jpg',\n",
              " 'train_00603.jpg',\n",
              " 'train_00604.jpg',\n",
              " 'train_00605.jpg',\n",
              " 'train_00606.jpg',\n",
              " 'train_00607.jpg',\n",
              " 'train_00608.jpg',\n",
              " 'train_00609.jpg',\n",
              " 'train_00610.jpg',\n",
              " 'train_00612.jpg',\n",
              " 'train_00613.jpg',\n",
              " 'train_00615.jpg',\n",
              " 'train_00616.jpg',\n",
              " 'train_00617.jpg',\n",
              " 'train_00618.jpg',\n",
              " 'train_00619.jpg',\n",
              " 'train_00620.jpg',\n",
              " 'train_00621.jpg',\n",
              " 'train_00622.jpg',\n",
              " 'train_00623.jpg',\n",
              " 'train_00624.jpg',\n",
              " 'train_00625.jpg',\n",
              " 'train_00626.jpg',\n",
              " 'train_00627.jpg',\n",
              " 'train_00628.jpg',\n",
              " 'train_00629.jpg',\n",
              " 'train_00630.jpg',\n",
              " 'train_00631.jpg',\n",
              " 'train_00632.jpg',\n",
              " 'train_00633.jpg',\n",
              " 'train_00634.jpg',\n",
              " 'train_00635.jpg',\n",
              " 'train_00637.jpg',\n",
              " 'train_00638.jpg',\n",
              " 'train_00639.jpg',\n",
              " 'train_00640.jpg',\n",
              " 'train_00641.jpg',\n",
              " 'train_00642.jpg',\n",
              " 'train_00643.jpg',\n",
              " 'train_00644.jpg',\n",
              " 'train_00645.jpg',\n",
              " 'train_00646.jpg',\n",
              " 'train_00647.jpg',\n",
              " 'train_00648.jpg',\n",
              " 'train_00649.jpg',\n",
              " 'train_00650.jpg',\n",
              " 'train_00651.jpg',\n",
              " 'train_00652.jpg',\n",
              " 'train_00653.jpg',\n",
              " 'train_00654.jpg',\n",
              " 'train_00655.jpg',\n",
              " 'train_00656.jpg',\n",
              " 'train_00657.jpg',\n",
              " 'train_00658.jpg',\n",
              " 'train_00659.jpg',\n",
              " 'train_00660.jpg',\n",
              " 'train_00661.jpg',\n",
              " 'train_00662.jpg',\n",
              " 'train_00663.jpg',\n",
              " 'train_00664.jpg',\n",
              " 'train_00665.jpg',\n",
              " 'train_00666.jpg',\n",
              " 'train_00667.jpg',\n",
              " 'train_00668.jpg',\n",
              " 'train_00669.jpg',\n",
              " 'train_00670.jpg',\n",
              " 'train_00671.jpg',\n",
              " 'train_00672.jpg',\n",
              " 'train_00673.jpg',\n",
              " 'train_00674.jpg',\n",
              " 'train_00675.jpg',\n",
              " 'train_00676.jpg',\n",
              " 'train_00677.jpg',\n",
              " 'train_00678.jpg',\n",
              " 'train_00679.jpg',\n",
              " 'train_00680.jpg',\n",
              " 'train_00681.jpg',\n",
              " 'train_00682.jpg',\n",
              " 'train_00683.jpg',\n",
              " 'train_00684.jpg',\n",
              " 'train_00685.jpg',\n",
              " 'train_00686.jpg',\n",
              " 'train_00687.jpg',\n",
              " 'train_00689.jpg',\n",
              " 'train_00690.jpg',\n",
              " 'train_00691.jpg',\n",
              " 'train_00692.jpg',\n",
              " 'train_00693.jpg',\n",
              " 'train_00694.jpg',\n",
              " 'train_00695.jpg',\n",
              " 'train_00696.jpg',\n",
              " 'train_00698.jpg',\n",
              " 'train_00699.jpg',\n",
              " 'train_00700.jpg',\n",
              " 'train_00701.jpg',\n",
              " 'train_00702.jpg',\n",
              " 'train_00703.jpg',\n",
              " 'train_00704.jpg',\n",
              " 'train_00706.jpg',\n",
              " 'train_00708.jpg',\n",
              " 'train_00709.jpg',\n",
              " 'train_00710.jpg',\n",
              " 'train_00711.jpg',\n",
              " 'train_00712.jpg',\n",
              " 'train_00713.jpg',\n",
              " 'train_00714.jpg',\n",
              " 'train_00715.jpg',\n",
              " 'train_00716.jpg',\n",
              " 'train_00717.jpg',\n",
              " 'train_00718.jpg',\n",
              " 'train_00719.jpg',\n",
              " 'train_00721.jpg',\n",
              " 'train_00723.jpg',\n",
              " 'train_00724.jpg',\n",
              " 'train_00725.jpg',\n",
              " 'train_00726.jpg',\n",
              " 'train_00727.jpg',\n",
              " 'train_00728.jpg',\n",
              " 'train_00729.jpg',\n",
              " 'train_00730.jpg',\n",
              " 'train_00731.jpg',\n",
              " 'train_00732.jpg',\n",
              " 'train_00733.jpg',\n",
              " 'train_00734.jpg',\n",
              " 'train_00735.jpg',\n",
              " 'train_00736.jpg',\n",
              " 'train_00737.jpg',\n",
              " 'train_00738.jpg',\n",
              " 'train_00739.jpg',\n",
              " 'train_00740.jpg',\n",
              " 'train_00741.jpg',\n",
              " 'train_00742.jpg',\n",
              " 'train_00743.jpg',\n",
              " 'train_00744.jpg',\n",
              " 'train_00745.jpg',\n",
              " 'train_00746.jpg',\n",
              " 'train_00747.jpg',\n",
              " 'train_00748.jpg',\n",
              " 'train_00749.jpg',\n",
              " 'train_00750.jpg',\n",
              " 'train_00751.jpg',\n",
              " 'train_00752.jpg',\n",
              " 'train_00753.jpg',\n",
              " 'train_00754.jpg',\n",
              " 'train_00755.jpg',\n",
              " 'train_00756.jpg',\n",
              " 'train_00757.jpg',\n",
              " 'train_00758.jpg',\n",
              " 'train_00759.jpg',\n",
              " 'train_00760.jpg',\n",
              " 'train_00762.jpg',\n",
              " 'train_00763.jpg',\n",
              " 'train_00764.jpg',\n",
              " 'train_00765.jpg',\n",
              " 'train_00766.jpg',\n",
              " 'train_00767.jpg',\n",
              " 'train_00768.jpg',\n",
              " 'train_00769.jpg',\n",
              " 'train_00770.jpg',\n",
              " 'train_00771.jpg',\n",
              " 'train_00772.jpg',\n",
              " 'train_00773.jpg',\n",
              " 'train_00774.jpg',\n",
              " 'train_00775.jpg',\n",
              " 'train_00776.jpg',\n",
              " 'train_00778.jpg',\n",
              " 'train_00779.jpg',\n",
              " 'train_00780.jpg',\n",
              " 'train_00781.jpg',\n",
              " 'train_00782.jpg',\n",
              " 'train_00783.jpg',\n",
              " 'train_00784.jpg',\n",
              " 'train_00785.jpg',\n",
              " 'train_00786.jpg',\n",
              " 'train_00787.jpg',\n",
              " 'train_00788.jpg',\n",
              " 'train_00789.jpg',\n",
              " 'train_00790.jpg',\n",
              " 'train_00791.jpg',\n",
              " 'train_00792.jpg',\n",
              " 'train_00793.jpg',\n",
              " 'train_00794.jpg',\n",
              " 'train_00795.jpg',\n",
              " 'train_00796.jpg',\n",
              " 'train_00797.jpg',\n",
              " 'train_00798.jpg',\n",
              " 'train_00799.jpg',\n",
              " 'train_00800.jpg',\n",
              " 'train_00801.jpg',\n",
              " 'train_00802.jpg',\n",
              " 'train_00803.jpg',\n",
              " 'train_00805.jpg',\n",
              " 'train_00806.jpg',\n",
              " 'train_00807.jpg',\n",
              " 'train_00808.jpg',\n",
              " 'train_00809.jpg',\n",
              " 'train_00810.jpg',\n",
              " 'train_00811.jpg',\n",
              " 'train_00812.jpg',\n",
              " 'train_00813.jpg',\n",
              " 'train_00814.jpg',\n",
              " 'train_00815.jpg',\n",
              " 'train_00816.jpg',\n",
              " 'train_00817.jpg',\n",
              " 'train_00818.jpg',\n",
              " 'train_00819.jpg',\n",
              " 'train_00820.jpg',\n",
              " 'train_00821.jpg',\n",
              " 'train_00822.jpg',\n",
              " 'train_00823.jpg',\n",
              " 'train_00824.jpg',\n",
              " 'train_00825.jpg',\n",
              " 'train_00826.jpg',\n",
              " 'train_00827.jpg',\n",
              " 'train_00828.jpg',\n",
              " 'train_00829.jpg',\n",
              " 'train_00830.jpg',\n",
              " 'train_00831.jpg',\n",
              " 'train_00832.jpg',\n",
              " 'train_00833.jpg',\n",
              " 'train_00836.jpg',\n",
              " 'train_00837.jpg',\n",
              " 'train_00838.jpg',\n",
              " 'train_00839.jpg',\n",
              " 'train_00840.jpg',\n",
              " 'train_00841.jpg',\n",
              " 'train_00842.jpg',\n",
              " 'train_00843.jpg',\n",
              " 'train_00844.jpg',\n",
              " 'train_00845.jpg',\n",
              " 'train_00846.jpg',\n",
              " 'train_00847.jpg',\n",
              " 'train_00848.jpg',\n",
              " 'train_00849.jpg',\n",
              " 'train_00850.jpg',\n",
              " 'train_00851.jpg',\n",
              " 'train_00852.jpg',\n",
              " 'train_00853.jpg',\n",
              " 'train_00854.jpg',\n",
              " 'train_00855.jpg',\n",
              " 'train_00856.jpg',\n",
              " 'train_00857.jpg',\n",
              " 'train_00858.jpg',\n",
              " 'train_00859.jpg',\n",
              " 'train_00860.jpg',\n",
              " 'train_00861.jpg',\n",
              " 'train_00863.jpg',\n",
              " 'train_00864.jpg',\n",
              " 'train_00865.jpg',\n",
              " 'train_00866.jpg',\n",
              " 'train_00867.jpg',\n",
              " 'train_00868.jpg',\n",
              " 'train_00869.jpg',\n",
              " 'train_00870.jpg',\n",
              " 'train_00871.jpg',\n",
              " 'train_00872.jpg',\n",
              " 'train_00873.jpg',\n",
              " 'train_00874.jpg',\n",
              " 'train_00875.jpg',\n",
              " 'train_00876.jpg',\n",
              " 'train_00877.jpg',\n",
              " 'train_00878.jpg',\n",
              " 'train_00879.jpg',\n",
              " 'train_00880.jpg',\n",
              " 'train_00881.jpg',\n",
              " 'train_00882.jpg',\n",
              " 'train_00883.jpg',\n",
              " 'train_00884.jpg',\n",
              " 'train_00885.jpg',\n",
              " 'train_00886.jpg',\n",
              " 'train_00887.jpg',\n",
              " 'train_00888.jpg',\n",
              " 'train_00889.jpg',\n",
              " 'train_00890.jpg',\n",
              " 'train_00891.jpg',\n",
              " 'train_00892.jpg',\n",
              " 'train_00893.jpg',\n",
              " 'train_00894.jpg',\n",
              " 'train_00895.jpg',\n",
              " 'train_00896.jpg',\n",
              " 'train_00897.jpg',\n",
              " 'train_00898.jpg',\n",
              " 'train_00899.jpg',\n",
              " 'train_00900.jpg',\n",
              " 'train_00901.jpg',\n",
              " 'train_00902.jpg',\n",
              " 'train_00903.jpg',\n",
              " 'train_00904.jpg',\n",
              " 'train_00905.jpg',\n",
              " 'train_00906.jpg',\n",
              " 'train_00907.jpg',\n",
              " 'train_00908.jpg',\n",
              " 'train_00909.jpg',\n",
              " 'train_00910.jpg',\n",
              " 'train_00911.jpg',\n",
              " 'train_00912.jpg',\n",
              " 'train_00913.jpg',\n",
              " 'train_00914.jpg',\n",
              " 'train_00915.jpg',\n",
              " 'train_00916.jpg',\n",
              " 'train_00917.jpg',\n",
              " 'train_00918.jpg',\n",
              " 'train_00919.jpg',\n",
              " 'train_00920.jpg',\n",
              " 'train_00921.jpg',\n",
              " 'train_00922.jpg',\n",
              " 'train_00923.jpg',\n",
              " 'train_00925.jpg',\n",
              " 'train_00927.jpg',\n",
              " 'train_00929.jpg',\n",
              " 'train_00930.jpg',\n",
              " 'train_00931.jpg',\n",
              " 'train_00932.jpg',\n",
              " 'train_00933.jpg',\n",
              " 'train_00934.jpg',\n",
              " 'train_00935.jpg',\n",
              " 'train_00936.jpg',\n",
              " 'train_00937.jpg',\n",
              " 'train_00938.jpg',\n",
              " 'train_00939.jpg',\n",
              " 'train_00940.jpg',\n",
              " 'train_00941.jpg',\n",
              " 'train_00942.jpg',\n",
              " 'train_00943.jpg',\n",
              " 'train_00944.jpg',\n",
              " 'train_00945.jpg',\n",
              " 'train_00946.jpg',\n",
              " 'train_00947.jpg',\n",
              " 'train_00948.jpg',\n",
              " 'train_00949.jpg',\n",
              " 'train_00950.jpg',\n",
              " 'train_00951.jpg',\n",
              " 'train_00952.jpg',\n",
              " 'train_00953.jpg',\n",
              " 'train_00954.jpg',\n",
              " 'train_00955.jpg',\n",
              " 'train_00956.jpg',\n",
              " 'train_00957.jpg',\n",
              " 'train_00958.jpg',\n",
              " 'train_00959.jpg',\n",
              " 'train_00960.jpg',\n",
              " 'train_00961.jpg',\n",
              " 'train_00962.jpg',\n",
              " 'train_00963.jpg',\n",
              " 'train_00964.jpg',\n",
              " 'train_00965.jpg',\n",
              " 'train_00966.jpg',\n",
              " 'train_00967.jpg',\n",
              " 'train_00968.jpg',\n",
              " 'train_00969.jpg',\n",
              " 'train_00970.jpg',\n",
              " 'train_00971.jpg',\n",
              " 'train_00972.jpg',\n",
              " 'train_00973.jpg',\n",
              " 'train_00974.jpg',\n",
              " 'train_00975.jpg',\n",
              " 'train_00976.jpg',\n",
              " 'train_00977.jpg',\n",
              " 'train_00978.jpg',\n",
              " 'train_00979.jpg',\n",
              " 'train_00981.jpg',\n",
              " 'train_00982.jpg',\n",
              " 'train_00983.jpg',\n",
              " 'train_00985.jpg',\n",
              " 'train_00986.jpg',\n",
              " 'train_00987.jpg',\n",
              " 'train_00988.jpg',\n",
              " 'train_00989.jpg',\n",
              " 'train_00990.jpg',\n",
              " 'train_00991.jpg',\n",
              " 'train_00992.jpg',\n",
              " 'train_00993.jpg',\n",
              " 'train_00994.jpg',\n",
              " 'train_00995.jpg',\n",
              " 'train_00996.jpg',\n",
              " 'train_00997.jpg',\n",
              " 'train_00999.jpg',\n",
              " 'train_01000.jpg',\n",
              " 'train_01001.jpg',\n",
              " 'train_01002.jpg',\n",
              " 'train_01003.jpg',\n",
              " 'train_01004.jpg',\n",
              " 'train_01005.jpg',\n",
              " 'train_01006.jpg',\n",
              " 'train_01007.jpg',\n",
              " 'train_01008.jpg',\n",
              " 'train_01009.jpg',\n",
              " 'train_01010.jpg',\n",
              " 'train_01011.jpg',\n",
              " 'train_01012.jpg',\n",
              " 'train_01013.jpg',\n",
              " 'train_01014.jpg',\n",
              " 'train_01015.jpg',\n",
              " 'train_01016.jpg',\n",
              " 'train_01017.jpg',\n",
              " 'train_01018.jpg',\n",
              " 'train_01019.jpg',\n",
              " 'train_01020.jpg',\n",
              " 'train_01021.jpg',\n",
              " 'train_01022.jpg',\n",
              " 'train_01023.jpg',\n",
              " 'train_01024.jpg',\n",
              " 'train_01025.jpg',\n",
              " 'train_01027.jpg',\n",
              " 'train_01028.jpg',\n",
              " 'train_01029.jpg',\n",
              " 'train_01030.jpg',\n",
              " 'train_01032.jpg',\n",
              " 'train_01033.jpg',\n",
              " 'train_01034.jpg',\n",
              " 'train_01035.jpg',\n",
              " 'train_01036.jpg',\n",
              " 'train_01037.jpg',\n",
              " 'train_01038.jpg',\n",
              " 'train_01039.jpg',\n",
              " 'train_01040.jpg',\n",
              " 'train_01042.jpg',\n",
              " 'train_01043.jpg',\n",
              " 'train_01044.jpg',\n",
              " 'train_01045.jpg',\n",
              " 'train_01046.jpg',\n",
              " 'train_01047.jpg',\n",
              " 'train_01048.jpg',\n",
              " 'train_01051.jpg',\n",
              " 'train_01052.jpg',\n",
              " 'train_01053.jpg',\n",
              " 'train_01054.jpg',\n",
              " 'train_01055.jpg',\n",
              " 'train_01056.jpg',\n",
              " 'train_01057.jpg',\n",
              " 'train_01058.jpg',\n",
              " 'train_01059.jpg',\n",
              " 'train_01060.jpg',\n",
              " 'train_01061.jpg',\n",
              " 'train_01062.jpg',\n",
              " 'train_01063.jpg',\n",
              " 'train_01064.jpg',\n",
              " 'train_01065.jpg',\n",
              " 'train_01066.jpg',\n",
              " 'train_01067.jpg',\n",
              " 'train_01068.jpg',\n",
              " 'train_01069.jpg',\n",
              " 'train_01070.jpg',\n",
              " 'train_01071.jpg',\n",
              " 'train_01072.jpg',\n",
              " 'train_01074.jpg',\n",
              " 'train_01075.jpg',\n",
              " 'train_01076.jpg',\n",
              " 'train_01077.jpg',\n",
              " 'train_01078.jpg',\n",
              " 'train_01079.jpg',\n",
              " 'train_01080.jpg',\n",
              " 'train_01081.jpg',\n",
              " 'train_01082.jpg',\n",
              " 'train_01083.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_name=[]\n",
        "\n",
        "for i in range(len(data_facial)):\n",
        "    data_name.append(data_facial[i][0])\n",
        "\n",
        "for i, (images, target, fn) in enumerate(train_loader):\n",
        "\n",
        "     facial_indx = []\n",
        "\n",
        "     for j in range(len(fn)):\n",
        "         if fn[j] in data_name:\n",
        "          facial_indx.append(data_name.index(fn[j]))\n",
        "         else:\n",
        "             print(f\"Value not found in data_name list: {fn[j]}\")\n",
        "             continue\n",
        "\n",
        "#     if not facial_indx:  # Check if the list is empty\n",
        "#         print(\"No valid indices found for this batch. Skipping...\")\n",
        "#         continue  # Skip the rest of the loop for this iteration\n",
        "\n",
        "     facial = data_facial[facial_indx, 1]\n",
        "    # facial = np.stack(facial, axis=0)\n",
        "    #images, rect, rect_local = pre_pro(images, facial, 0.8, 0.5, 5, 2)\n"
      ],
      "metadata": {
        "id": "gtQboK32gS5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facial.shape"
      ],
      "metadata": {
        "id": "KwfcdseMFkar",
        "outputId": "7b30a037-437a-4305-e97c-3527d77af3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([[ 66.290855,  64.71174 ],\n",
              "              [166.51279 ,  66.73897 ],\n",
              "              [103.795296, 137.5376  ],\n",
              "              [ 67.526474, 164.25757 ],\n",
              "              [151.81087 , 166.88293 ]], dtype=float32),\n",
              "       array([[ 52.574024,  72.08543 ],\n",
              "              [170.28488 ,  75.83313 ],\n",
              "              [ 97.66755 , 146.42345 ],\n",
              "              [ 59.979824, 169.03072 ],\n",
              "              [152.00728 , 174.85385 ]], dtype=float32),\n",
              "       array([[ 55.469723,  74.459595],\n",
              "              [174.28455 ,  76.047165],\n",
              "              [106.45209 , 129.48306 ],\n",
              "              [ 61.57117 , 163.38625 ],\n",
              "              [148.67355 , 170.31339 ]], dtype=float32),\n",
              "       array([[ 62.60553 ,  75.39979 ],\n",
              "              [160.5791  ,  70.416084],\n",
              "              [119.88296 , 114.45027 ],\n",
              "              [ 67.544395, 162.71452 ],\n",
              "              [152.44237 , 161.15994 ]], dtype=float32),\n",
              "       array([[ 56.84479,  77.49987],\n",
              "              [162.81818,  69.522  ],\n",
              "              [117.60535, 140.5801 ],\n",
              "              [ 72.37067, 173.39323],\n",
              "              [152.81755, 168.63599]], dtype=float32),\n",
              "       array([[ 54.12359 ,  75.123474],\n",
              "              [159.35376 ,  69.77018 ],\n",
              "              [ 90.28213 , 109.543816],\n",
              "              [ 56.42197 , 162.7932  ],\n",
              "              [151.73848 , 162.63795 ]], dtype=float32),\n",
              "       array([[ 59.012524,  79.03611 ],\n",
              "              [170.60097 ,  77.446396],\n",
              "              [119.098145, 102.62258 ],\n",
              "              [ 73.72336 , 174.64322 ],\n",
              "              [166.00203 , 176.34706 ]], dtype=float32),\n",
              "       array([[ 62.311874,  66.171974],\n",
              "              [166.56439 ,  64.70779 ],\n",
              "              [120.274765,  99.005775],\n",
              "              [ 59.878723, 164.29544 ],\n",
              "              [163.66957 , 160.75757 ]], dtype=float32),\n",
              "       array([[ 62.83145 ,  76.27361 ],\n",
              "              [163.44464 ,  77.01016 ],\n",
              "              [117.32637 , 136.84634 ],\n",
              "              [ 62.043472, 168.69615 ],\n",
              "              [149.6774  , 170.22314 ]], dtype=float32),\n",
              "       array([[ 55.340122,  78.276695],\n",
              "              [165.86835 ,  78.158745],\n",
              "              [103.240974, 114.474686],\n",
              "              [ 53.401924, 168.20709 ],\n",
              "              [169.18462 , 168.4136  ]], dtype=float32),\n",
              "       array([[ 60.49685,  78.07244],\n",
              "              [162.8282 ,  80.58145],\n",
              "              [109.95565, 133.83112],\n",
              "              [ 67.40771, 167.87329],\n",
              "              [146.76509, 171.2489 ]], dtype=float32),\n",
              "       array([[ 57.325214,  82.99748 ],\n",
              "              [158.68973 ,  80.513664],\n",
              "              [ 92.896614, 119.04857 ],\n",
              "              [ 63.572292, 166.65865 ],\n",
              "              [155.88829 , 166.23035 ]], dtype=float32),\n",
              "       array([[ 50.566544,  72.94823 ],\n",
              "              [156.38203 ,  76.74969 ],\n",
              "              [ 84.50238 , 118.15366 ],\n",
              "              [ 54.84494 , 156.63748 ],\n",
              "              [144.11566 , 160.9866  ]], dtype=float32),\n",
              "       array([[ 64.40782,  73.90244],\n",
              "              [167.43727,  78.47472],\n",
              "              [114.93278, 124.24251],\n",
              "              [ 72.07848, 176.54065],\n",
              "              [146.4177 , 185.76404]], dtype=float32),\n",
              "       array([[ 53.60718 ,  74.95537 ],\n",
              "              [156.05695 ,  76.81557 ],\n",
              "              [ 88.159996, 116.75984 ],\n",
              "              [ 65.58439 , 163.48894 ],\n",
              "              [150.83183 , 165.0979  ]], dtype=float32)], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn"
      ],
      "metadata": {
        "id": "zR379EaDEJBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_name"
      ],
      "metadata": {
        "id": "ANlOEs9FD5DL",
        "outputId": "ece38447-962a-44ce-9e03-7fa13d229fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_00001.jpg',\n",
              " 'train_00002.jpg',\n",
              " 'train_00003.jpg',\n",
              " 'train_00004.jpg',\n",
              " 'train_00005.jpg',\n",
              " 'train_00006.jpg',\n",
              " 'train_00007.jpg',\n",
              " 'train_00008.jpg',\n",
              " 'train_00009.jpg',\n",
              " 'train_00010.jpg',\n",
              " 'train_00011.jpg',\n",
              " 'train_00012.jpg',\n",
              " 'train_00013.jpg',\n",
              " 'train_00014.jpg',\n",
              " 'train_00016.jpg',\n",
              " 'train_00018.jpg',\n",
              " 'train_00019.jpg',\n",
              " 'train_00020.jpg',\n",
              " 'train_00021.jpg',\n",
              " 'train_00022.jpg',\n",
              " 'train_00023.jpg',\n",
              " 'train_00024.jpg',\n",
              " 'train_00025.jpg',\n",
              " 'train_00026.jpg',\n",
              " 'train_00027.jpg',\n",
              " 'train_00028.jpg',\n",
              " 'train_00029.jpg',\n",
              " 'train_00030.jpg',\n",
              " 'train_00031.jpg',\n",
              " 'train_00032.jpg',\n",
              " 'train_00034.jpg',\n",
              " 'train_00035.jpg',\n",
              " 'train_00036.jpg',\n",
              " 'train_00037.jpg',\n",
              " 'train_00038.jpg',\n",
              " 'train_00040.jpg',\n",
              " 'train_00041.jpg',\n",
              " 'train_00042.jpg',\n",
              " 'train_00044.jpg',\n",
              " 'train_00045.jpg',\n",
              " 'train_00046.jpg',\n",
              " 'train_00047.jpg',\n",
              " 'train_00048.jpg',\n",
              " 'train_00049.jpg',\n",
              " 'train_00050.jpg',\n",
              " 'train_00051.jpg',\n",
              " 'train_00052.jpg',\n",
              " 'train_00053.jpg',\n",
              " 'train_00054.jpg',\n",
              " 'train_00055.jpg',\n",
              " 'train_00056.jpg',\n",
              " 'train_00057.jpg',\n",
              " 'train_00058.jpg',\n",
              " 'train_00059.jpg',\n",
              " 'train_00060.jpg',\n",
              " 'train_00061.jpg',\n",
              " 'train_00062.jpg',\n",
              " 'train_00063.jpg',\n",
              " 'train_00064.jpg',\n",
              " 'train_00065.jpg',\n",
              " 'train_00066.jpg',\n",
              " 'train_00067.jpg',\n",
              " 'train_00068.jpg',\n",
              " 'train_00069.jpg',\n",
              " 'train_00070.jpg',\n",
              " 'train_00071.jpg',\n",
              " 'train_00072.jpg',\n",
              " 'train_00073.jpg',\n",
              " 'train_00074.jpg',\n",
              " 'train_00075.jpg',\n",
              " 'train_00076.jpg',\n",
              " 'train_00077.jpg',\n",
              " 'train_00078.jpg',\n",
              " 'train_00081.jpg',\n",
              " 'train_00082.jpg',\n",
              " 'train_00083.jpg',\n",
              " 'train_00084.jpg',\n",
              " 'train_00085.jpg',\n",
              " 'train_00086.jpg',\n",
              " 'train_00087.jpg',\n",
              " 'train_00088.jpg',\n",
              " 'train_00089.jpg',\n",
              " 'train_00090.jpg',\n",
              " 'train_00092.jpg',\n",
              " 'train_00093.jpg',\n",
              " 'train_00094.jpg',\n",
              " 'train_00095.jpg',\n",
              " 'train_00096.jpg',\n",
              " 'train_00097.jpg',\n",
              " 'train_00098.jpg',\n",
              " 'train_00099.jpg',\n",
              " 'train_00100.jpg',\n",
              " 'train_00101.jpg',\n",
              " 'train_00102.jpg',\n",
              " 'train_00103.jpg',\n",
              " 'train_00104.jpg',\n",
              " 'train_00106.jpg',\n",
              " 'train_00107.jpg',\n",
              " 'train_00109.jpg',\n",
              " 'train_00110.jpg',\n",
              " 'train_00111.jpg',\n",
              " 'train_00112.jpg',\n",
              " 'train_00113.jpg',\n",
              " 'train_00114.jpg',\n",
              " 'train_00116.jpg',\n",
              " 'train_00117.jpg',\n",
              " 'train_00118.jpg',\n",
              " 'train_00119.jpg',\n",
              " 'train_00120.jpg',\n",
              " 'train_00121.jpg',\n",
              " 'train_00122.jpg',\n",
              " 'train_00123.jpg',\n",
              " 'train_00124.jpg',\n",
              " 'train_00125.jpg',\n",
              " 'train_00126.jpg',\n",
              " 'train_00129.jpg',\n",
              " 'train_00130.jpg',\n",
              " 'train_00131.jpg',\n",
              " 'train_00132.jpg',\n",
              " 'train_00133.jpg',\n",
              " 'train_00134.jpg',\n",
              " 'train_00135.jpg',\n",
              " 'train_00136.jpg',\n",
              " 'train_00137.jpg',\n",
              " 'train_00138.jpg',\n",
              " 'train_00139.jpg',\n",
              " 'train_00140.jpg',\n",
              " 'train_00141.jpg',\n",
              " 'train_00142.jpg',\n",
              " 'train_00143.jpg',\n",
              " 'train_00144.jpg',\n",
              " 'train_00145.jpg',\n",
              " 'train_00146.jpg',\n",
              " 'train_00147.jpg',\n",
              " 'train_00148.jpg',\n",
              " 'train_00149.jpg',\n",
              " 'train_00150.jpg',\n",
              " 'train_00151.jpg',\n",
              " 'train_00152.jpg',\n",
              " 'train_00153.jpg',\n",
              " 'train_00154.jpg',\n",
              " 'train_00155.jpg',\n",
              " 'train_00156.jpg',\n",
              " 'train_00158.jpg',\n",
              " 'train_00159.jpg',\n",
              " 'train_00160.jpg',\n",
              " 'train_00162.jpg',\n",
              " 'train_00163.jpg',\n",
              " 'train_00165.jpg',\n",
              " 'train_00166.jpg',\n",
              " 'train_00167.jpg',\n",
              " 'train_00168.jpg',\n",
              " 'train_00169.jpg',\n",
              " 'train_00170.jpg',\n",
              " 'train_00171.jpg',\n",
              " 'train_00172.jpg',\n",
              " 'train_00173.jpg',\n",
              " 'train_00174.jpg',\n",
              " 'train_00175.jpg',\n",
              " 'train_00176.jpg',\n",
              " 'train_00177.jpg',\n",
              " 'train_00178.jpg',\n",
              " 'train_00179.jpg',\n",
              " 'train_00181.jpg',\n",
              " 'train_00182.jpg',\n",
              " 'train_00183.jpg',\n",
              " 'train_00184.jpg',\n",
              " 'train_00185.jpg',\n",
              " 'train_00186.jpg',\n",
              " 'train_00187.jpg',\n",
              " 'train_00188.jpg',\n",
              " 'train_00189.jpg',\n",
              " 'train_00190.jpg',\n",
              " 'train_00191.jpg',\n",
              " 'train_00192.jpg',\n",
              " 'train_00193.jpg',\n",
              " 'train_00194.jpg',\n",
              " 'train_00195.jpg',\n",
              " 'train_00196.jpg',\n",
              " 'train_00197.jpg',\n",
              " 'train_00198.jpg',\n",
              " 'train_00199.jpg',\n",
              " 'train_00200.jpg',\n",
              " 'train_00201.jpg',\n",
              " 'train_00202.jpg',\n",
              " 'train_00203.jpg',\n",
              " 'train_00204.jpg',\n",
              " 'train_00205.jpg',\n",
              " 'train_00207.jpg',\n",
              " 'train_00208.jpg',\n",
              " 'train_00209.jpg',\n",
              " 'train_00210.jpg',\n",
              " 'train_00211.jpg',\n",
              " 'train_00212.jpg',\n",
              " 'train_00213.jpg',\n",
              " 'train_00214.jpg',\n",
              " 'train_00215.jpg',\n",
              " 'train_00216.jpg',\n",
              " 'train_00217.jpg',\n",
              " 'train_00218.jpg',\n",
              " 'train_00219.jpg',\n",
              " 'train_00220.jpg',\n",
              " 'train_00221.jpg',\n",
              " 'train_00222.jpg',\n",
              " 'train_00223.jpg',\n",
              " 'train_00224.jpg',\n",
              " 'train_00225.jpg',\n",
              " 'train_00226.jpg',\n",
              " 'train_00227.jpg',\n",
              " 'train_00228.jpg',\n",
              " 'train_00230.jpg',\n",
              " 'train_00231.jpg',\n",
              " 'train_00233.jpg',\n",
              " 'train_00234.jpg',\n",
              " 'train_00235.jpg',\n",
              " 'train_00236.jpg',\n",
              " 'train_00237.jpg',\n",
              " 'train_00238.jpg',\n",
              " 'train_00239.jpg',\n",
              " 'train_00240.jpg',\n",
              " 'train_00241.jpg',\n",
              " 'train_00243.jpg',\n",
              " 'train_00244.jpg',\n",
              " 'train_00245.jpg',\n",
              " 'train_00246.jpg',\n",
              " 'train_00247.jpg',\n",
              " 'train_00248.jpg',\n",
              " 'train_00249.jpg',\n",
              " 'train_00250.jpg',\n",
              " 'train_00251.jpg',\n",
              " 'train_00252.jpg',\n",
              " 'train_00253.jpg',\n",
              " 'train_00254.jpg',\n",
              " 'train_00255.jpg',\n",
              " 'train_00256.jpg',\n",
              " 'train_00257.jpg',\n",
              " 'train_00258.jpg',\n",
              " 'train_00259.jpg',\n",
              " 'train_00260.jpg',\n",
              " 'train_00261.jpg',\n",
              " 'train_00262.jpg',\n",
              " 'train_00264.jpg',\n",
              " 'train_00265.jpg',\n",
              " 'train_00266.jpg',\n",
              " 'train_00267.jpg',\n",
              " 'train_00269.jpg',\n",
              " 'train_00270.jpg',\n",
              " 'train_00271.jpg',\n",
              " 'train_00272.jpg',\n",
              " 'train_00273.jpg',\n",
              " 'train_00274.jpg',\n",
              " 'train_00275.jpg',\n",
              " 'train_00276.jpg',\n",
              " 'train_00277.jpg',\n",
              " 'train_00278.jpg',\n",
              " 'train_00279.jpg',\n",
              " 'train_00280.jpg',\n",
              " 'train_00281.jpg',\n",
              " 'train_00282.jpg',\n",
              " 'train_00284.jpg',\n",
              " 'train_00285.jpg',\n",
              " 'train_00287.jpg',\n",
              " 'train_00290.jpg',\n",
              " 'train_00291.jpg',\n",
              " 'train_00293.jpg',\n",
              " 'train_00294.jpg',\n",
              " 'train_00295.jpg',\n",
              " 'train_00296.jpg',\n",
              " 'train_00297.jpg',\n",
              " 'train_00298.jpg',\n",
              " 'train_00299.jpg',\n",
              " 'train_00300.jpg',\n",
              " 'train_00302.jpg',\n",
              " 'train_00303.jpg',\n",
              " 'train_00304.jpg',\n",
              " 'train_00305.jpg',\n",
              " 'train_00306.jpg',\n",
              " 'train_00307.jpg',\n",
              " 'train_00308.jpg',\n",
              " 'train_00309.jpg',\n",
              " 'train_00310.jpg',\n",
              " 'train_00311.jpg',\n",
              " 'train_00312.jpg',\n",
              " 'train_00313.jpg',\n",
              " 'train_00314.jpg',\n",
              " 'train_00315.jpg',\n",
              " 'train_00317.jpg',\n",
              " 'train_00318.jpg',\n",
              " 'train_00319.jpg',\n",
              " 'train_00320.jpg',\n",
              " 'train_00321.jpg',\n",
              " 'train_00322.jpg',\n",
              " 'train_00323.jpg',\n",
              " 'train_00324.jpg',\n",
              " 'train_00326.jpg',\n",
              " 'train_00327.jpg',\n",
              " 'train_00328.jpg',\n",
              " 'train_00329.jpg',\n",
              " 'train_00330.jpg',\n",
              " 'train_00331.jpg',\n",
              " 'train_00332.jpg',\n",
              " 'train_00333.jpg',\n",
              " 'train_00334.jpg',\n",
              " 'train_00335.jpg',\n",
              " 'train_00336.jpg',\n",
              " 'train_00337.jpg',\n",
              " 'train_00338.jpg',\n",
              " 'train_00340.jpg',\n",
              " 'train_00341.jpg',\n",
              " 'train_00342.jpg',\n",
              " 'train_00343.jpg',\n",
              " 'train_00344.jpg',\n",
              " 'train_00345.jpg',\n",
              " 'train_00346.jpg',\n",
              " 'train_00347.jpg',\n",
              " 'train_00348.jpg',\n",
              " 'train_00349.jpg',\n",
              " 'train_00350.jpg',\n",
              " 'train_00351.jpg',\n",
              " 'train_00352.jpg',\n",
              " 'train_00353.jpg',\n",
              " 'train_00354.jpg',\n",
              " 'train_00355.jpg',\n",
              " 'train_00357.jpg',\n",
              " 'train_00359.jpg',\n",
              " 'train_00360.jpg',\n",
              " 'train_00361.jpg',\n",
              " 'train_00362.jpg',\n",
              " 'train_00363.jpg',\n",
              " 'train_00365.jpg',\n",
              " 'train_00366.jpg',\n",
              " 'train_00367.jpg',\n",
              " 'train_00368.jpg',\n",
              " 'train_00369.jpg',\n",
              " 'train_00370.jpg',\n",
              " 'train_00371.jpg',\n",
              " 'train_00372.jpg',\n",
              " 'train_00374.jpg',\n",
              " 'train_00375.jpg',\n",
              " 'train_00376.jpg',\n",
              " 'train_00377.jpg',\n",
              " 'train_00378.jpg',\n",
              " 'train_00379.jpg',\n",
              " 'train_00380.jpg',\n",
              " 'train_00381.jpg',\n",
              " 'train_00382.jpg',\n",
              " 'train_00383.jpg',\n",
              " 'train_00384.jpg',\n",
              " 'train_00385.jpg',\n",
              " 'train_00387.jpg',\n",
              " 'train_00388.jpg',\n",
              " 'train_00389.jpg',\n",
              " 'train_00390.jpg',\n",
              " 'train_00391.jpg',\n",
              " 'train_00392.jpg',\n",
              " 'train_00393.jpg',\n",
              " 'train_00394.jpg',\n",
              " 'train_00395.jpg',\n",
              " 'train_00396.jpg',\n",
              " 'train_00397.jpg',\n",
              " 'train_00398.jpg',\n",
              " 'train_00399.jpg',\n",
              " 'train_00400.jpg',\n",
              " 'train_00401.jpg',\n",
              " 'train_00402.jpg',\n",
              " 'train_00403.jpg',\n",
              " 'train_00404.jpg',\n",
              " 'train_00405.jpg',\n",
              " 'train_00406.jpg',\n",
              " 'train_00407.jpg',\n",
              " 'train_00408.jpg',\n",
              " 'train_00409.jpg',\n",
              " 'train_00410.jpg',\n",
              " 'train_00411.jpg',\n",
              " 'train_00412.jpg',\n",
              " 'train_00414.jpg',\n",
              " 'train_00415.jpg',\n",
              " 'train_00416.jpg',\n",
              " 'train_00417.jpg',\n",
              " 'train_00418.jpg',\n",
              " 'train_00419.jpg',\n",
              " 'train_00420.jpg',\n",
              " 'train_00421.jpg',\n",
              " 'train_00422.jpg',\n",
              " 'train_00423.jpg',\n",
              " 'train_00424.jpg',\n",
              " 'train_00425.jpg',\n",
              " 'train_00426.jpg',\n",
              " 'train_00427.jpg',\n",
              " 'train_00430.jpg',\n",
              " 'train_00431.jpg',\n",
              " 'train_00432.jpg',\n",
              " 'train_00433.jpg',\n",
              " 'train_00434.jpg',\n",
              " 'train_00435.jpg',\n",
              " 'train_00438.jpg',\n",
              " 'train_00439.jpg',\n",
              " 'train_00440.jpg',\n",
              " 'train_00441.jpg',\n",
              " 'train_00442.jpg',\n",
              " 'train_00443.jpg',\n",
              " 'train_00444.jpg',\n",
              " 'train_00445.jpg',\n",
              " 'train_00446.jpg',\n",
              " 'train_00447.jpg',\n",
              " 'train_00448.jpg',\n",
              " 'train_00449.jpg',\n",
              " 'train_00450.jpg',\n",
              " 'train_00451.jpg',\n",
              " 'train_00453.jpg',\n",
              " 'train_00454.jpg',\n",
              " 'train_00455.jpg',\n",
              " 'train_00456.jpg',\n",
              " 'train_00457.jpg',\n",
              " 'train_00458.jpg',\n",
              " 'train_00459.jpg',\n",
              " 'train_00461.jpg',\n",
              " 'train_00462.jpg',\n",
              " 'train_00463.jpg',\n",
              " 'train_00464.jpg',\n",
              " 'train_00465.jpg',\n",
              " 'train_00466.jpg',\n",
              " 'train_00467.jpg',\n",
              " 'train_00468.jpg',\n",
              " 'train_00469.jpg',\n",
              " 'train_00470.jpg',\n",
              " 'train_00471.jpg',\n",
              " 'train_00472.jpg',\n",
              " 'train_00473.jpg',\n",
              " 'train_00474.jpg',\n",
              " 'train_00475.jpg',\n",
              " 'train_00476.jpg',\n",
              " 'train_00477.jpg',\n",
              " 'train_00478.jpg',\n",
              " 'train_00479.jpg',\n",
              " 'train_00480.jpg',\n",
              " 'train_00481.jpg',\n",
              " 'train_00482.jpg',\n",
              " 'train_00483.jpg',\n",
              " 'train_00484.jpg',\n",
              " 'train_00485.jpg',\n",
              " 'train_00486.jpg',\n",
              " 'train_00487.jpg',\n",
              " 'train_00488.jpg',\n",
              " 'train_00489.jpg',\n",
              " 'train_00490.jpg',\n",
              " 'train_00491.jpg',\n",
              " 'train_00493.jpg',\n",
              " 'train_00494.jpg',\n",
              " 'train_00496.jpg',\n",
              " 'train_00498.jpg',\n",
              " 'train_00499.jpg',\n",
              " 'train_00500.jpg',\n",
              " 'train_00501.jpg',\n",
              " 'train_00502.jpg',\n",
              " 'train_00503.jpg',\n",
              " 'train_00504.jpg',\n",
              " 'train_00505.jpg',\n",
              " 'train_00506.jpg',\n",
              " 'train_00507.jpg',\n",
              " 'train_00508.jpg',\n",
              " 'train_00509.jpg',\n",
              " 'train_00510.jpg',\n",
              " 'train_00512.jpg',\n",
              " 'train_00513.jpg',\n",
              " 'train_00514.jpg',\n",
              " 'train_00516.jpg',\n",
              " 'train_00517.jpg',\n",
              " 'train_00518.jpg',\n",
              " 'train_00519.jpg',\n",
              " 'train_00520.jpg',\n",
              " 'train_00521.jpg',\n",
              " 'train_00522.jpg',\n",
              " 'train_00523.jpg',\n",
              " 'train_00524.jpg',\n",
              " 'train_00525.jpg',\n",
              " 'train_00527.jpg',\n",
              " 'train_00528.jpg',\n",
              " 'train_00529.jpg',\n",
              " 'train_00530.jpg',\n",
              " 'train_00531.jpg',\n",
              " 'train_00532.jpg',\n",
              " 'train_00533.jpg',\n",
              " 'train_00534.jpg',\n",
              " 'train_00535.jpg',\n",
              " 'train_00536.jpg',\n",
              " 'train_00538.jpg',\n",
              " 'train_00539.jpg',\n",
              " 'train_00540.jpg',\n",
              " 'train_00541.jpg',\n",
              " 'train_00542.jpg',\n",
              " 'train_00543.jpg',\n",
              " 'train_00544.jpg',\n",
              " 'train_00545.jpg',\n",
              " 'train_00546.jpg',\n",
              " 'train_00547.jpg',\n",
              " 'train_00548.jpg',\n",
              " 'train_00549.jpg',\n",
              " 'train_00550.jpg',\n",
              " 'train_00552.jpg',\n",
              " 'train_00553.jpg',\n",
              " 'train_00555.jpg',\n",
              " 'train_00556.jpg',\n",
              " 'train_00557.jpg',\n",
              " 'train_00558.jpg',\n",
              " 'train_00559.jpg',\n",
              " 'train_00560.jpg',\n",
              " 'train_00561.jpg',\n",
              " 'train_00562.jpg',\n",
              " 'train_00563.jpg',\n",
              " 'train_00564.jpg',\n",
              " 'train_00565.jpg',\n",
              " 'train_00566.jpg',\n",
              " 'train_00567.jpg',\n",
              " 'train_00568.jpg',\n",
              " 'train_00569.jpg',\n",
              " 'train_00570.jpg',\n",
              " 'train_00571.jpg',\n",
              " 'train_00572.jpg',\n",
              " 'train_00573.jpg',\n",
              " 'train_00574.jpg',\n",
              " 'train_00575.jpg',\n",
              " 'train_00576.jpg',\n",
              " 'train_00577.jpg',\n",
              " 'train_00578.jpg',\n",
              " 'train_00579.jpg',\n",
              " 'train_00580.jpg',\n",
              " 'train_00582.jpg',\n",
              " 'train_00583.jpg',\n",
              " 'train_00584.jpg',\n",
              " 'train_00585.jpg',\n",
              " 'train_00587.jpg',\n",
              " 'train_00588.jpg',\n",
              " 'train_00589.jpg',\n",
              " 'train_00590.jpg',\n",
              " 'train_00591.jpg',\n",
              " 'train_00592.jpg',\n",
              " 'train_00594.jpg',\n",
              " 'train_00595.jpg',\n",
              " 'train_00596.jpg',\n",
              " 'train_00597.jpg',\n",
              " 'train_00598.jpg',\n",
              " 'train_00599.jpg',\n",
              " 'train_00600.jpg',\n",
              " 'train_00601.jpg',\n",
              " 'train_00602.jpg',\n",
              " 'train_00603.jpg',\n",
              " 'train_00604.jpg',\n",
              " 'train_00605.jpg',\n",
              " 'train_00606.jpg',\n",
              " 'train_00607.jpg',\n",
              " 'train_00608.jpg',\n",
              " 'train_00609.jpg',\n",
              " 'train_00610.jpg',\n",
              " 'train_00612.jpg',\n",
              " 'train_00613.jpg',\n",
              " 'train_00615.jpg',\n",
              " 'train_00616.jpg',\n",
              " 'train_00617.jpg',\n",
              " 'train_00618.jpg',\n",
              " 'train_00619.jpg',\n",
              " 'train_00620.jpg',\n",
              " 'train_00621.jpg',\n",
              " 'train_00622.jpg',\n",
              " 'train_00623.jpg',\n",
              " 'train_00624.jpg',\n",
              " 'train_00625.jpg',\n",
              " 'train_00626.jpg',\n",
              " 'train_00627.jpg',\n",
              " 'train_00628.jpg',\n",
              " 'train_00629.jpg',\n",
              " 'train_00630.jpg',\n",
              " 'train_00631.jpg',\n",
              " 'train_00632.jpg',\n",
              " 'train_00633.jpg',\n",
              " 'train_00634.jpg',\n",
              " 'train_00635.jpg',\n",
              " 'train_00637.jpg',\n",
              " 'train_00638.jpg',\n",
              " 'train_00639.jpg',\n",
              " 'train_00640.jpg',\n",
              " 'train_00641.jpg',\n",
              " 'train_00642.jpg',\n",
              " 'train_00643.jpg',\n",
              " 'train_00644.jpg',\n",
              " 'train_00645.jpg',\n",
              " 'train_00646.jpg',\n",
              " 'train_00647.jpg',\n",
              " 'train_00648.jpg',\n",
              " 'train_00649.jpg',\n",
              " 'train_00650.jpg',\n",
              " 'train_00651.jpg',\n",
              " 'train_00652.jpg',\n",
              " 'train_00653.jpg',\n",
              " 'train_00654.jpg',\n",
              " 'train_00655.jpg',\n",
              " 'train_00656.jpg',\n",
              " 'train_00657.jpg',\n",
              " 'train_00658.jpg',\n",
              " 'train_00659.jpg',\n",
              " 'train_00660.jpg',\n",
              " 'train_00661.jpg',\n",
              " 'train_00662.jpg',\n",
              " 'train_00663.jpg',\n",
              " 'train_00664.jpg',\n",
              " 'train_00665.jpg',\n",
              " 'train_00666.jpg',\n",
              " 'train_00667.jpg',\n",
              " 'train_00668.jpg',\n",
              " 'train_00669.jpg',\n",
              " 'train_00670.jpg',\n",
              " 'train_00671.jpg',\n",
              " 'train_00672.jpg',\n",
              " 'train_00673.jpg',\n",
              " 'train_00674.jpg',\n",
              " 'train_00675.jpg',\n",
              " 'train_00676.jpg',\n",
              " 'train_00677.jpg',\n",
              " 'train_00678.jpg',\n",
              " 'train_00679.jpg',\n",
              " 'train_00680.jpg',\n",
              " 'train_00681.jpg',\n",
              " 'train_00682.jpg',\n",
              " 'train_00683.jpg',\n",
              " 'train_00684.jpg',\n",
              " 'train_00685.jpg',\n",
              " 'train_00686.jpg',\n",
              " 'train_00687.jpg',\n",
              " 'train_00689.jpg',\n",
              " 'train_00690.jpg',\n",
              " 'train_00691.jpg',\n",
              " 'train_00692.jpg',\n",
              " 'train_00693.jpg',\n",
              " 'train_00694.jpg',\n",
              " 'train_00695.jpg',\n",
              " 'train_00696.jpg',\n",
              " 'train_00698.jpg',\n",
              " 'train_00699.jpg',\n",
              " 'train_00700.jpg',\n",
              " 'train_00701.jpg',\n",
              " 'train_00702.jpg',\n",
              " 'train_00703.jpg',\n",
              " 'train_00704.jpg',\n",
              " 'train_00706.jpg',\n",
              " 'train_00708.jpg',\n",
              " 'train_00709.jpg',\n",
              " 'train_00710.jpg',\n",
              " 'train_00711.jpg',\n",
              " 'train_00712.jpg',\n",
              " 'train_00713.jpg',\n",
              " 'train_00714.jpg',\n",
              " 'train_00715.jpg',\n",
              " 'train_00716.jpg',\n",
              " 'train_00717.jpg',\n",
              " 'train_00718.jpg',\n",
              " 'train_00719.jpg',\n",
              " 'train_00721.jpg',\n",
              " 'train_00723.jpg',\n",
              " 'train_00724.jpg',\n",
              " 'train_00725.jpg',\n",
              " 'train_00726.jpg',\n",
              " 'train_00727.jpg',\n",
              " 'train_00728.jpg',\n",
              " 'train_00729.jpg',\n",
              " 'train_00730.jpg',\n",
              " 'train_00731.jpg',\n",
              " 'train_00732.jpg',\n",
              " 'train_00733.jpg',\n",
              " 'train_00734.jpg',\n",
              " 'train_00735.jpg',\n",
              " 'train_00736.jpg',\n",
              " 'train_00737.jpg',\n",
              " 'train_00738.jpg',\n",
              " 'train_00739.jpg',\n",
              " 'train_00740.jpg',\n",
              " 'train_00741.jpg',\n",
              " 'train_00742.jpg',\n",
              " 'train_00743.jpg',\n",
              " 'train_00744.jpg',\n",
              " 'train_00745.jpg',\n",
              " 'train_00746.jpg',\n",
              " 'train_00747.jpg',\n",
              " 'train_00748.jpg',\n",
              " 'train_00749.jpg',\n",
              " 'train_00750.jpg',\n",
              " 'train_00751.jpg',\n",
              " 'train_00752.jpg',\n",
              " 'train_00753.jpg',\n",
              " 'train_00754.jpg',\n",
              " 'train_00755.jpg',\n",
              " 'train_00756.jpg',\n",
              " 'train_00757.jpg',\n",
              " 'train_00758.jpg',\n",
              " 'train_00759.jpg',\n",
              " 'train_00760.jpg',\n",
              " 'train_00762.jpg',\n",
              " 'train_00763.jpg',\n",
              " 'train_00764.jpg',\n",
              " 'train_00765.jpg',\n",
              " 'train_00766.jpg',\n",
              " 'train_00767.jpg',\n",
              " 'train_00768.jpg',\n",
              " 'train_00769.jpg',\n",
              " 'train_00770.jpg',\n",
              " 'train_00771.jpg',\n",
              " 'train_00772.jpg',\n",
              " 'train_00773.jpg',\n",
              " 'train_00774.jpg',\n",
              " 'train_00775.jpg',\n",
              " 'train_00776.jpg',\n",
              " 'train_00778.jpg',\n",
              " 'train_00779.jpg',\n",
              " 'train_00780.jpg',\n",
              " 'train_00781.jpg',\n",
              " 'train_00782.jpg',\n",
              " 'train_00783.jpg',\n",
              " 'train_00784.jpg',\n",
              " 'train_00785.jpg',\n",
              " 'train_00786.jpg',\n",
              " 'train_00787.jpg',\n",
              " 'train_00788.jpg',\n",
              " 'train_00789.jpg',\n",
              " 'train_00790.jpg',\n",
              " 'train_00791.jpg',\n",
              " 'train_00792.jpg',\n",
              " 'train_00793.jpg',\n",
              " 'train_00794.jpg',\n",
              " 'train_00795.jpg',\n",
              " 'train_00796.jpg',\n",
              " 'train_00797.jpg',\n",
              " 'train_00798.jpg',\n",
              " 'train_00799.jpg',\n",
              " 'train_00800.jpg',\n",
              " 'train_00801.jpg',\n",
              " 'train_00802.jpg',\n",
              " 'train_00803.jpg',\n",
              " 'train_00805.jpg',\n",
              " 'train_00806.jpg',\n",
              " 'train_00807.jpg',\n",
              " 'train_00808.jpg',\n",
              " 'train_00809.jpg',\n",
              " 'train_00810.jpg',\n",
              " 'train_00811.jpg',\n",
              " 'train_00812.jpg',\n",
              " 'train_00813.jpg',\n",
              " 'train_00814.jpg',\n",
              " 'train_00815.jpg',\n",
              " 'train_00816.jpg',\n",
              " 'train_00817.jpg',\n",
              " 'train_00818.jpg',\n",
              " 'train_00819.jpg',\n",
              " 'train_00820.jpg',\n",
              " 'train_00821.jpg',\n",
              " 'train_00822.jpg',\n",
              " 'train_00823.jpg',\n",
              " 'train_00824.jpg',\n",
              " 'train_00825.jpg',\n",
              " 'train_00826.jpg',\n",
              " 'train_00827.jpg',\n",
              " 'train_00828.jpg',\n",
              " 'train_00829.jpg',\n",
              " 'train_00830.jpg',\n",
              " 'train_00831.jpg',\n",
              " 'train_00832.jpg',\n",
              " 'train_00833.jpg',\n",
              " 'train_00836.jpg',\n",
              " 'train_00837.jpg',\n",
              " 'train_00838.jpg',\n",
              " 'train_00839.jpg',\n",
              " 'train_00840.jpg',\n",
              " 'train_00841.jpg',\n",
              " 'train_00842.jpg',\n",
              " 'train_00843.jpg',\n",
              " 'train_00844.jpg',\n",
              " 'train_00845.jpg',\n",
              " 'train_00846.jpg',\n",
              " 'train_00847.jpg',\n",
              " 'train_00848.jpg',\n",
              " 'train_00849.jpg',\n",
              " 'train_00850.jpg',\n",
              " 'train_00851.jpg',\n",
              " 'train_00852.jpg',\n",
              " 'train_00853.jpg',\n",
              " 'train_00854.jpg',\n",
              " 'train_00855.jpg',\n",
              " 'train_00856.jpg',\n",
              " 'train_00857.jpg',\n",
              " 'train_00858.jpg',\n",
              " 'train_00859.jpg',\n",
              " 'train_00860.jpg',\n",
              " 'train_00861.jpg',\n",
              " 'train_00863.jpg',\n",
              " 'train_00864.jpg',\n",
              " 'train_00865.jpg',\n",
              " 'train_00866.jpg',\n",
              " 'train_00867.jpg',\n",
              " 'train_00868.jpg',\n",
              " 'train_00869.jpg',\n",
              " 'train_00870.jpg',\n",
              " 'train_00871.jpg',\n",
              " 'train_00872.jpg',\n",
              " 'train_00873.jpg',\n",
              " 'train_00874.jpg',\n",
              " 'train_00875.jpg',\n",
              " 'train_00876.jpg',\n",
              " 'train_00877.jpg',\n",
              " 'train_00878.jpg',\n",
              " 'train_00879.jpg',\n",
              " 'train_00880.jpg',\n",
              " 'train_00881.jpg',\n",
              " 'train_00882.jpg',\n",
              " 'train_00883.jpg',\n",
              " 'train_00884.jpg',\n",
              " 'train_00885.jpg',\n",
              " 'train_00886.jpg',\n",
              " 'train_00887.jpg',\n",
              " 'train_00888.jpg',\n",
              " 'train_00889.jpg',\n",
              " 'train_00890.jpg',\n",
              " 'train_00891.jpg',\n",
              " 'train_00892.jpg',\n",
              " 'train_00893.jpg',\n",
              " 'train_00894.jpg',\n",
              " 'train_00895.jpg',\n",
              " 'train_00896.jpg',\n",
              " 'train_00897.jpg',\n",
              " 'train_00898.jpg',\n",
              " 'train_00899.jpg',\n",
              " 'train_00900.jpg',\n",
              " 'train_00901.jpg',\n",
              " 'train_00902.jpg',\n",
              " 'train_00903.jpg',\n",
              " 'train_00904.jpg',\n",
              " 'train_00905.jpg',\n",
              " 'train_00906.jpg',\n",
              " 'train_00907.jpg',\n",
              " 'train_00908.jpg',\n",
              " 'train_00909.jpg',\n",
              " 'train_00910.jpg',\n",
              " 'train_00911.jpg',\n",
              " 'train_00912.jpg',\n",
              " 'train_00913.jpg',\n",
              " 'train_00914.jpg',\n",
              " 'train_00915.jpg',\n",
              " 'train_00916.jpg',\n",
              " 'train_00917.jpg',\n",
              " 'train_00918.jpg',\n",
              " 'train_00919.jpg',\n",
              " 'train_00920.jpg',\n",
              " 'train_00921.jpg',\n",
              " 'train_00922.jpg',\n",
              " 'train_00923.jpg',\n",
              " 'train_00925.jpg',\n",
              " 'train_00927.jpg',\n",
              " 'train_00929.jpg',\n",
              " 'train_00930.jpg',\n",
              " 'train_00931.jpg',\n",
              " 'train_00932.jpg',\n",
              " 'train_00933.jpg',\n",
              " 'train_00934.jpg',\n",
              " 'train_00935.jpg',\n",
              " 'train_00936.jpg',\n",
              " 'train_00937.jpg',\n",
              " 'train_00938.jpg',\n",
              " 'train_00939.jpg',\n",
              " 'train_00940.jpg',\n",
              " 'train_00941.jpg',\n",
              " 'train_00942.jpg',\n",
              " 'train_00943.jpg',\n",
              " 'train_00944.jpg',\n",
              " 'train_00945.jpg',\n",
              " 'train_00946.jpg',\n",
              " 'train_00947.jpg',\n",
              " 'train_00948.jpg',\n",
              " 'train_00949.jpg',\n",
              " 'train_00950.jpg',\n",
              " 'train_00951.jpg',\n",
              " 'train_00952.jpg',\n",
              " 'train_00953.jpg',\n",
              " 'train_00954.jpg',\n",
              " 'train_00955.jpg',\n",
              " 'train_00956.jpg',\n",
              " 'train_00957.jpg',\n",
              " 'train_00958.jpg',\n",
              " 'train_00959.jpg',\n",
              " 'train_00960.jpg',\n",
              " 'train_00961.jpg',\n",
              " 'train_00962.jpg',\n",
              " 'train_00963.jpg',\n",
              " 'train_00964.jpg',\n",
              " 'train_00965.jpg',\n",
              " 'train_00966.jpg',\n",
              " 'train_00967.jpg',\n",
              " 'train_00968.jpg',\n",
              " 'train_00969.jpg',\n",
              " 'train_00970.jpg',\n",
              " 'train_00971.jpg',\n",
              " 'train_00972.jpg',\n",
              " 'train_00973.jpg',\n",
              " 'train_00974.jpg',\n",
              " 'train_00975.jpg',\n",
              " 'train_00976.jpg',\n",
              " 'train_00977.jpg',\n",
              " 'train_00978.jpg',\n",
              " 'train_00979.jpg',\n",
              " 'train_00981.jpg',\n",
              " 'train_00982.jpg',\n",
              " 'train_00983.jpg',\n",
              " 'train_00985.jpg',\n",
              " 'train_00986.jpg',\n",
              " 'train_00987.jpg',\n",
              " 'train_00988.jpg',\n",
              " 'train_00989.jpg',\n",
              " 'train_00990.jpg',\n",
              " 'train_00991.jpg',\n",
              " 'train_00992.jpg',\n",
              " 'train_00993.jpg',\n",
              " 'train_00994.jpg',\n",
              " 'train_00995.jpg',\n",
              " 'train_00996.jpg',\n",
              " 'train_00997.jpg',\n",
              " 'train_00999.jpg',\n",
              " 'train_01000.jpg',\n",
              " 'train_01001.jpg',\n",
              " 'train_01002.jpg',\n",
              " 'train_01003.jpg',\n",
              " 'train_01004.jpg',\n",
              " 'train_01005.jpg',\n",
              " 'train_01006.jpg',\n",
              " 'train_01007.jpg',\n",
              " 'train_01008.jpg',\n",
              " 'train_01009.jpg',\n",
              " 'train_01010.jpg',\n",
              " 'train_01011.jpg',\n",
              " 'train_01012.jpg',\n",
              " 'train_01013.jpg',\n",
              " 'train_01014.jpg',\n",
              " 'train_01015.jpg',\n",
              " 'train_01016.jpg',\n",
              " 'train_01017.jpg',\n",
              " 'train_01018.jpg',\n",
              " 'train_01019.jpg',\n",
              " 'train_01020.jpg',\n",
              " 'train_01021.jpg',\n",
              " 'train_01022.jpg',\n",
              " 'train_01023.jpg',\n",
              " 'train_01024.jpg',\n",
              " 'train_01025.jpg',\n",
              " 'train_01027.jpg',\n",
              " 'train_01028.jpg',\n",
              " 'train_01029.jpg',\n",
              " 'train_01030.jpg',\n",
              " 'train_01032.jpg',\n",
              " 'train_01033.jpg',\n",
              " 'train_01034.jpg',\n",
              " 'train_01035.jpg',\n",
              " 'train_01036.jpg',\n",
              " 'train_01037.jpg',\n",
              " 'train_01038.jpg',\n",
              " 'train_01039.jpg',\n",
              " 'train_01040.jpg',\n",
              " 'train_01042.jpg',\n",
              " 'train_01043.jpg',\n",
              " 'train_01044.jpg',\n",
              " 'train_01045.jpg',\n",
              " 'train_01046.jpg',\n",
              " 'train_01047.jpg',\n",
              " 'train_01048.jpg',\n",
              " 'train_01051.jpg',\n",
              " 'train_01052.jpg',\n",
              " 'train_01053.jpg',\n",
              " 'train_01054.jpg',\n",
              " 'train_01055.jpg',\n",
              " 'train_01056.jpg',\n",
              " 'train_01057.jpg',\n",
              " 'train_01058.jpg',\n",
              " 'train_01059.jpg',\n",
              " 'train_01060.jpg',\n",
              " 'train_01061.jpg',\n",
              " 'train_01062.jpg',\n",
              " 'train_01063.jpg',\n",
              " 'train_01064.jpg',\n",
              " 'train_01065.jpg',\n",
              " 'train_01066.jpg',\n",
              " 'train_01067.jpg',\n",
              " 'train_01068.jpg',\n",
              " 'train_01069.jpg',\n",
              " 'train_01070.jpg',\n",
              " 'train_01071.jpg',\n",
              " 'train_01072.jpg',\n",
              " 'train_01074.jpg',\n",
              " 'train_01075.jpg',\n",
              " 'train_01076.jpg',\n",
              " 'train_01077.jpg',\n",
              " 'train_01078.jpg',\n",
              " 'train_01079.jpg',\n",
              " 'train_01080.jpg',\n",
              " 'train_01081.jpg',\n",
              " 'train_01082.jpg',\n",
              " 'train_01083.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    args= init()\n",
        "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    print('Training time: ' + now.strftime(\"%m-%d %H:%M\"))\n",
        "\n",
        "    # create model\n",
        "    model_cla = resnet.resnet50()\n",
        "    model_cla.fc = nn.Linear(2048, 12666)\n",
        "    model_cla = torch.nn.DataParallel(model_cla)\n",
        "    model_cla.to(device)\n",
        "    # pretrianed on msceleb\n",
        "    #checkpoint = torch.load('/content/drive/MyDrive/FER/Pre_trained/resnet50_pretrained_on_msceleb.pth.tar')\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/Test_FER/Pre_trained/resnet50_pretrained_on_msceleb.pth.tar' , map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "\n",
        "    pre_trained_dict = checkpoint['state_dict']\n",
        "    model_dict = model_cla.state_dict()\n",
        "    for k, v in pre_trained_dict.items():\n",
        "        if k in model_dict:\n",
        "            print(k, v.shape)\n",
        "    pretrained_dict = {k: v for k, v in pre_trained_dict.items() if k in model_dict}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_cla.load_state_dict(model_dict)\n",
        "    model_cla.module.fc = nn.Linear(64*3, 7)\n",
        "    #model_cla.module.fc = nn.Linear(256*3, 7)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "\n",
        "    # criterion_val = nn.CrossEntropyLoss().cuda()\n",
        "    # criterion_train =  nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    criterion_val = nn.CrossEntropyLoss()\n",
        "    criterion_train =  nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model_cla.parameters(),\n",
        "                                args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay\n",
        "                                )\n",
        "\n",
        "    recorder = RecorderMeter(args.epochs)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            args.start_epoch = checkpoint['epoch']\n",
        "            best_acc = checkpoint['best_acc']\n",
        "            recorder = checkpoint['recorder']\n",
        "            best_acc = best_acc.to()\n",
        "            model_cla.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Data loading code\n",
        "\n",
        "    traindir = os.path.join(args.data, 'Train')\n",
        "    valdir = os.path.join(args.data, 'Test')\n",
        "\n",
        "\n",
        "    # RAF-DB\n",
        "    normalize = transforms.Normalize(mean=[0.5758095, 0.4500876, 0.40176094],\n",
        "                                      std=[0.20888616, 0.19142343, 0.18289249])\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(traindir,\n",
        "                                         transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                             transforms.RandomHorizontalFlip(),\n",
        "                                                             transforms.ToTensor(),\n",
        "                                                             normalize]))\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(valdir,\n",
        "                                        transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                            transforms.ToTensor(),\n",
        "                                                            normalize]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=args.workers,\n",
        "                                               pin_memory=True)\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size=args.batch_size,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=args.workers,\n",
        "                                             pin_memory=True)\n",
        "\n",
        "    if args.evaluate:\n",
        "        checkpoint = torch.load(args.evaluate_path)\n",
        "        model_cla.load_state_dict(checkpoint['state_dict'])\n",
        "        validate(val_loader, model_cla, criterion_val, args)\n",
        "        return\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        start_time = time.time()\n",
        "        # update learning rate\n",
        "        current_learning_rate = adjust_learning_rate(optimizer, epoch, args)\n",
        "        print('Current learning rate: ', current_learning_rate)\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write('Current learning rate: ' + str(current_learning_rate) + '\\n')\n",
        "\n",
        "        # train for one epoch\n",
        "        train_acc, train_los = train(train_loader, model_cla, criterion_train, optimizer, epoch, args)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        val_acc, val_los = validate(val_loader, model_cla, criterion_val, args)\n",
        "\n",
        "        recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n",
        "        curve_name = args.log_path + '-log.png'\n",
        "        recorder.plot_curve(curve_name)\n",
        "\n",
        "        # remember best acc and save checkpoint\n",
        "        is_best = val_acc > best_acc\n",
        "        best_acc = max(val_acc, best_acc)\n",
        "\n",
        "        print('Current best accuracy: ', best_acc.item())\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write('Current best accuracy: ' + str(best_acc.item()) + '\\n')\n",
        "\n",
        "        save_checkpoint({'state_dict': model_cla.state_dict()}, is_best, args)\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        print(\"An Epoch Time: \", epoch_time)\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write(str(epoch_time) + '\\n')\n",
        "        # scheduler.step(val_acc)\n",
        "\n",
        "def train(train_loader, model_cla, criterion, optimizer, epoch, args):\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
        "    progress = ProgressMeter(len(train_loader),\n",
        "                             [losses, top1],\n",
        "                             prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "\n",
        "    # switch mode\n",
        "    model_cla.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "\n",
        "        # length = len(images)\n",
        "        images = images\n",
        "        target = target\n",
        "        # compute output\n",
        "        x_1, x_2, x_3, x_fc1, x_fc2, x_fc3, output = model_cla(images)\n",
        "        x_fc1 = soft_max(x_fc1)\n",
        "        x_fc2 = soft_max(x_fc2)\n",
        "        x_fc3 = soft_max(x_fc3)\n",
        "        # compute loss\n",
        "        loss_softmax = criterion(output, target)\n",
        "        loss_orthognal = orthognal_loss(x_fc1, x_fc2, x_fc3)\n",
        "        loss = loss_softmax + 0.2 * loss_orthognal\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, _ = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss and accuracy\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i, args)\n",
        "\n",
        "    return top1.avg, losses.avg\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, args):\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
        "    progress = ProgressMeter(len(val_loader),\n",
        "                             [losses, top1],\n",
        "                             prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            images = images\n",
        "            target = target\n",
        "\n",
        "            # compute output\n",
        "            x_1, x_2, x_3, x_fc1, x_fc2, x_fc3, output = model(images)\n",
        "            loss_softmax = criterion(output, target)\n",
        "            x_fc1 = soft_max(x_fc1)\n",
        "            x_fc2 = soft_max(x_fc2)\n",
        "            x_fc3 = soft_max(x_fc3)\n",
        "            loss_orthognal = orthognal_loss(x_fc1, x_fc2, x_fc3)\n",
        "            loss = loss_softmax + 0.2 * loss_orthognal\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, _ = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(i, args)\n",
        "\n",
        "        print(' *** Accuracy {top1.avg:.3f}  *** '.format(top1=top1))\n",
        "        with open(args.log_path + '-log.txt', 'a') as f:\n",
        "            f.write(' * Accuracy {top1.avg:.3f}'.format(top1=top1) + '\\n')\n",
        "    return top1.avg, losses.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, args):\n",
        "    torch.save(state, args.checkpoint_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(args.checkpoint_path, args.best_checkpoint_path)\n",
        "\n",
        "\n",
        "def orthognal_loss(x, y, z):\n",
        "    x = F.normalize(x, p=2, dim=1)\n",
        "    y = F.normalize(y, p=2, dim=1)\n",
        "    z = F.normalize(z, p=2, dim=1)\n",
        "    l_12 = torch.sum(x*y, dim=1)\n",
        "    l_13 = torch.sum(x*z, dim=1)\n",
        "    l_23 = torch.sum(y*z, dim=1)\n",
        "    return torch.mean((l_12+l_13+l_23)/3, dim=-1)"
      ],
      "metadata": {
        "id": "P4jOq10eLWL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Min_Upload**"
      ],
      "metadata": {
        "id": "R_iXsbLkeXmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B8e5uapZuRG"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from locale import normalize\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import random\n",
        "import numbers\n",
        "import torch.nn.functional as F\n",
        "import resnet_v1 as resnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many GPUs are available\n",
        "num_gpus = torch.cuda.device_count()\n",
        "print(f'Number of GPUs available: {num_gpus}')"
      ],
      "metadata": {
        "id": "hYYfxTCNPa27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "NcnAWIjS2zoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "time_str = now.strftime(\"[%m-%d]-[%H-%M]-\")"
      ],
      "metadata": {
        "id": "h7Wbi3VBerVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Test_FER/Dataset/RAFDB/Train.zip"
      ],
      "metadata": {
        "id": "UCM5zozjNzbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Test_FER/Dataset/RAFDB/Test.zip"
      ],
      "metadata": {
        "id": "A1v1Ud8iPOCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")"
      ],
      "metadata": {
        "id": "C-S2s5gDb8nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n"
      ],
      "metadata": {
        "id": "E9WTWUsEfLDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch, args):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print_txt = '\\t'.join(entries)\n",
        "        print(print_txt)\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write(print_txt + '\\n')\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    lr = args.lr * (args.factor ** (epoch // args.af))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            # .contiguous\n",
        "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "x8Ne6M9gfMsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecorderMeter(object):\n",
        "    \"\"\"Computes and stores the minimum loss value and its epoch index\"\"\"\n",
        "\n",
        "    def __init__(self, total_epoch):\n",
        "        self.reset(total_epoch)\n",
        "\n",
        "    def reset(self, total_epoch):\n",
        "        self.total_epoch = total_epoch\n",
        "        self.current_epoch = 0\n",
        "        self.epoch_losses = np.zeros((self.total_epoch, 2), dtype=np.float32)    # [epoch, train/val]\n",
        "        self.epoch_accuracy = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
        "\n",
        "    def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n",
        "        self.epoch_losses[idx, 0] = train_loss * 30\n",
        "        self.epoch_losses[idx, 1] = val_loss * 30\n",
        "        self.epoch_accuracy[idx, 0] = train_acc\n",
        "        self.epoch_accuracy[idx, 1] = val_acc\n",
        "        self.current_epoch = idx + 1\n",
        "\n",
        "    def plot_curve(self, save_path):\n",
        "\n",
        "        title = 'the accuracy/loss curve of train/val'\n",
        "        dpi = 80\n",
        "        width, height = 1800, 800\n",
        "        legend_fontsize = 10\n",
        "        figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        x_axis = np.array([i for i in range(self.total_epoch)])  # epochs\n",
        "        y_axis = np.zeros(self.total_epoch)\n",
        "\n",
        "        plt.xlim(0, self.total_epoch)\n",
        "        plt.ylim(0, 100)\n",
        "        interval_y = 5\n",
        "        interval_x = 5\n",
        "        plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n",
        "        plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n",
        "        plt.grid()\n",
        "        plt.title(title, fontsize=20)\n",
        "        plt.xlabel('the training epoch', fontsize=16)\n",
        "        plt.ylabel('accuracy', fontsize=16)\n",
        "\n",
        "        y_axis[:] = self.epoch_accuracy[:, 0]\n",
        "        plt.plot(x_axis, y_axis, color='g', linestyle='-', label='train-accuracy', lw=2)\n",
        "        plt.legend(loc=4, fontsize=legend_fontsize)\n",
        "\n",
        "        y_axis[:] = self.epoch_accuracy[:, 1]\n",
        "        plt.plot(x_axis, y_axis, color='y', linestyle='-', label='valid-accuracy', lw=2)\n",
        "        plt.legend(loc=4, fontsize=legend_fontsize)\n",
        "\n",
        "        y_axis[:] = self.epoch_losses[:, 0]\n",
        "        plt.plot(x_axis, y_axis, color='g', linestyle=':', label='train-loss-x30', lw=2)\n",
        "        plt.legend(loc=4, fontsize=legend_fontsize)\n",
        "\n",
        "        y_axis[:] = self.epoch_losses[:, 1]\n",
        "        plt.plot(x_axis, y_axis, color='y', linestyle=':', label='valid-loss-x30', lw=2)\n",
        "        plt.legend(loc=4, fontsize=legend_fontsize)\n",
        "\n",
        "        if save_path is not None:\n",
        "            fig.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
        "            print('Saved figure')\n",
        "        plt.close(fig)"
      ],
      "metadata": {
        "id": "ixUlTGemfR4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    args= init()\n",
        "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    print('Training time: ' + now.strftime(\"%m-%d %H:%M\"))\n",
        "\n",
        "    # create model\n",
        "    model_cla = resnet.resnet50()\n",
        "    model_cla.fc = nn.Linear(2048, 12666)\n",
        "    model_cla = torch.nn.DataParallel(model_cla)\n",
        "    model_cla.to(device)\n",
        "    # pretrianed on msceleb\n",
        "    #checkpoint = torch.load('/content/drive/MyDrive/FER/Pre_trained/resnet50_pretrained_on_msceleb.pth.tar')\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/Test_FER/Pre_trained/resnet50_pretrained_on_msceleb.pth.tar' , map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "\n",
        "    pre_trained_dict = checkpoint['state_dict']\n",
        "    model_dict = model_cla.state_dict()\n",
        "    for k, v in pre_trained_dict.items():\n",
        "        if k in model_dict:\n",
        "            print(k, v.shape)\n",
        "    pretrained_dict = {k: v for k, v in pre_trained_dict.items() if k in model_dict}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_cla.load_state_dict(model_dict)\n",
        "    model_cla.module.fc = nn.Linear(64*3, 7)\n",
        "    #model_cla.module.fc = nn.Linear(256*3, 7)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "\n",
        "    # criterion_val = nn.CrossEntropyLoss().cuda()\n",
        "    # criterion_train =  nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    criterion_val = nn.CrossEntropyLoss()\n",
        "    criterion_train =  nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model_cla.parameters(),\n",
        "                                args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay\n",
        "                                )\n",
        "\n",
        "    recorder = RecorderMeter(args.epochs)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            args.start_epoch = checkpoint['epoch']\n",
        "            best_acc = checkpoint['best_acc']\n",
        "            recorder = checkpoint['recorder']\n",
        "            best_acc = best_acc.to()\n",
        "            model_cla.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Data loading code\n",
        "\n",
        "    traindir = os.path.join(args.data, 'Train')\n",
        "    valdir = os.path.join(args.data, 'Test')\n",
        "\n",
        "\n",
        "    # RAF-DB\n",
        "    normalize = transforms.Normalize(mean=[0.5758095, 0.4500876, 0.40176094],\n",
        "                                      std=[0.20888616, 0.19142343, 0.18289249])\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(traindir,\n",
        "                                         transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                             transforms.RandomHorizontalFlip(),\n",
        "                                                             transforms.ToTensor(),\n",
        "                                                             normalize]))\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(valdir,\n",
        "                                        transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                            transforms.ToTensor(),\n",
        "                                                            normalize]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=args.workers,\n",
        "                                               pin_memory=True)\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size=args.batch_size,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=args.workers,\n",
        "                                             pin_memory=True)\n",
        "\n",
        "    if args.evaluate:\n",
        "        checkpoint = torch.load(args.evaluate_path)\n",
        "        model_cla.load_state_dict(checkpoint['state_dict'])\n",
        "        validate(val_loader, model_cla, criterion_val, args)\n",
        "        return\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        start_time = time.time()\n",
        "        # update learning rate\n",
        "        current_learning_rate = adjust_learning_rate(optimizer, epoch, args)\n",
        "        print('Current learning rate: ', current_learning_rate)\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write('Current learning rate: ' + str(current_learning_rate) + '\\n')\n",
        "\n",
        "        # train for one epoch\n",
        "        train_acc, train_los = train(train_loader, model_cla, criterion_train, optimizer, epoch, args)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        val_acc, val_los = validate(val_loader, model_cla, criterion_val, args)\n",
        "\n",
        "        recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n",
        "        curve_name = args.log_path + '-log.png'\n",
        "        recorder.plot_curve(curve_name)\n",
        "\n",
        "        # remember best acc and save checkpoint\n",
        "        is_best = val_acc > best_acc\n",
        "        best_acc = max(val_acc, best_acc)\n",
        "\n",
        "        print('Current best accuracy: ', best_acc.item())\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write('Current best accuracy: ' + str(best_acc.item()) + '\\n')\n",
        "\n",
        "        save_checkpoint({'state_dict': model_cla.state_dict()}, is_best, args)\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        print(\"An Epoch Time: \", epoch_time)\n",
        "        txt_name = args.log_path + '-log.txt'\n",
        "        with open(txt_name, 'a') as f:\n",
        "            f.write(str(epoch_time) + '\\n')\n",
        "        # scheduler.step(val_acc)\n",
        "\n",
        "def train(train_loader, model_cla, criterion, optimizer, epoch, args):\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
        "    progress = ProgressMeter(len(train_loader),\n",
        "                             [losses, top1],\n",
        "                             prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "\n",
        "    # switch mode\n",
        "    model_cla.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "\n",
        "        # length = len(images)\n",
        "        images = images\n",
        "        target = target\n",
        "        # compute output\n",
        "        x_1, x_2, x_3, x_fc1, x_fc2, x_fc3, output = model_cla(images)\n",
        "        x_fc1 = soft_max(x_fc1)\n",
        "        x_fc2 = soft_max(x_fc2)\n",
        "        x_fc3 = soft_max(x_fc3)\n",
        "        # compute loss\n",
        "        loss_softmax = criterion(output, target)\n",
        "        loss_orthognal = orthognal_loss(x_fc1, x_fc2, x_fc3)\n",
        "        loss = loss_softmax + 0.2 * loss_orthognal\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, _ = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss and accuracy\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i, args)\n",
        "\n",
        "    return top1.avg, losses.avg\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, args):\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
        "    progress = ProgressMeter(len(val_loader),\n",
        "                             [losses, top1],\n",
        "                             prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            images = images\n",
        "            target = target\n",
        "\n",
        "            # compute output\n",
        "            x_1, x_2, x_3, x_fc1, x_fc2, x_fc3, output = model(images)\n",
        "            loss_softmax = criterion(output, target)\n",
        "            x_fc1 = soft_max(x_fc1)\n",
        "            x_fc2 = soft_max(x_fc2)\n",
        "            x_fc3 = soft_max(x_fc3)\n",
        "            loss_orthognal = orthognal_loss(x_fc1, x_fc2, x_fc3)\n",
        "            loss = loss_softmax + 0.2 * loss_orthognal\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, _ = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(i, args)\n",
        "\n",
        "        print(' *** Accuracy {top1.avg:.3f}  *** '.format(top1=top1))\n",
        "        with open(args.log_path + '-log.txt', 'a') as f:\n",
        "            f.write(' * Accuracy {top1.avg:.3f}'.format(top1=top1) + '\\n')\n",
        "    return top1.avg, losses.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, args):\n",
        "    torch.save(state, args.checkpoint_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(args.checkpoint_path, args.best_checkpoint_path)\n",
        "\n",
        "\n",
        "def orthognal_loss(x, y, z):\n",
        "    x = F.normalize(x, p=2, dim=1)\n",
        "    y = F.normalize(y, p=2, dim=1)\n",
        "    z = F.normalize(z, p=2, dim=1)\n",
        "    l_12 = torch.sum(x*y, dim=1)\n",
        "    l_13 = torch.sum(x*z, dim=1)\n",
        "    l_23 = torch.sum(y*z, dim=1)\n",
        "    return torch.mean((l_12+l_13+l_23)/3, dim=-1)"
      ],
      "metadata": {
        "id": "CJsPosKJe3Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "FHWWbArzfZ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main_generate_ortho**"
      ],
      "metadata": {
        "id": "N0cAq65cetl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload a pathon file with some useful functions\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "JiMboOfQezqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import datetime\n",
        "import resnet_v1 as resnet"
      ],
      "metadata": {
        "id": "MhFGht6lgNVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many GPUs are available\n",
        "num_gpus = torch.cuda.device_count()\n",
        "print(f'Number of GPUs available: {num_gpus}')"
      ],
      "metadata": {
        "id": "dicuN0Tye57N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "time_str = now.strftime(\"[%m-%d]-[%H-%M]-\")"
      ],
      "metadata": {
        "id": "4pUn-UHZe_Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/FER/Dataset/RAFDB/Train.zip"
      ],
      "metadata": {
        "id": "xly2j6IzhAsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Test_FER/Dataset/RAFDB/Test.zip"
      ],
      "metadata": {
        "id": "h9iKabk_hLjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init():\n",
        "\n",
        "  parser = argparse.ArgumentParser(description=\"PyTorch\")\n",
        "\n",
        "  parser.add_argument('--data', type=str, default='/content/RAFDB/')\n",
        "  parser.add_argument('-j', '--workers', default=4, type=int, metavar='N', help='number of data loading workers')\n",
        "  parser.add_argument('-b', '--batch-size', default=8, type=int, metavar='N')\n",
        "\n",
        "  args = parser.parse_args(args=[])\n",
        "  return args"
      ],
      "metadata": {
        "id": "858rk6wxfbbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            # .contiguousè®©åœ°å€è¿žç»­\n",
        "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)"
      ],
      "metadata": {
        "id": "tVYIHpVihww4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    args= init()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_acc = 0\n",
        "\n",
        "    print('Training time: ' + now.strftime(\"%m-%d %H:%M\"))\n",
        "\n",
        "    # create model\n",
        "    model_cla = resnet.resnet50()\n",
        "    model_cla = torch.nn.DataParallel(model_cla).cuda()\n",
        "    model_cla.to(device)\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/FER/checkpoint_cnn/RAFDB/[08-15]-[18-09]-model_best.pth.tar')\n",
        "    pre_trained_dict = checkpoint['state_dict']\n",
        "    for k, v in pre_trained_dict.items():\n",
        "        print(k, v.shape)\n",
        "    model_cla.load_state_dict(pre_trained_dict)\n",
        "\n",
        "    # Data loading code\n",
        "    traindir = os.path.join(args.data, 'Train')\n",
        "    valdir = os.path.join(args.data, 'Test')\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.5758095, 0.4500876, 0.40176094],\n",
        "                                      std=[0.20888616, 0.19142343, 0.18289249])\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(traindir,\n",
        "                                         transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                             transforms.RandomHorizontalFlip(),\n",
        "                                                             transforms.ToTensor(),\n",
        "                                                             normalize]))\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(valdir,\n",
        "                                        transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                                            transforms.ToTensor(),\n",
        "                                                            normalize]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=args.workers,\n",
        "                                               pin_memory=True)\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size=args.batch_size,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=args.workers,\n",
        "                                             pin_memory=True)\n",
        "    model_cla.eval()\n",
        "    feature_1 = []\n",
        "    feature_2 = []\n",
        "    feature_3 = []\n",
        "    label = []\n",
        "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "            # compute output\n",
        "            x_1, x_2, x_3, x_fc1, x_fc2, x_fc3, output = model_cla(images)\n",
        "            acc1, _ = accuracy(output, target, topk=(1, 5))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            x_1 = x_1.permute(0, 2, 3, 1)\n",
        "            x_2 = x_2.permute(0, 2, 3, 1)\n",
        "            x_3 = x_3.permute(0, 2, 3, 1)\n",
        "            if i == 0:\n",
        "                feature_1 = x_1.cpu().numpy()\n",
        "                feature_2 = x_2.cpu().numpy()\n",
        "                feature_3 = x_3.cpu().numpy()\n",
        "                label = target.cpu().numpy()\n",
        "            else:\n",
        "                feature_1 = np.concatenate((feature_1, x_1.cpu().numpy()),axis=0)\n",
        "                feature_2 = np.concatenate((feature_2, x_2.cpu().numpy()),axis=0)\n",
        "                feature_3 = np.concatenate((feature_3, x_3.cpu().numpy()),axis=0)\n",
        "                label = np.concatenate((label, target.cpu().numpy()),axis=0)\n",
        "\n",
        "        print(' *** Accuracy {top1.avg:.3f}  *** '.format(top1=top1))\n",
        "    # train\n",
        "    # np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/train_1_RAFDB2_v1.npy\",feature_1)\n",
        "    # np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/train_2_RAFDB2_v1.npy\",feature_2)\n",
        "    # np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/train_3_RAFDB2_v1.npy\",feature_3)\n",
        "    # np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/train_label_RAFDB2_v1.npy\",label)\n",
        "    # # test\n",
        "    np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/test_1_RAFDB2_v1.npy\",feature_1)\n",
        "    np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/test_2_RAFDB2_v1.npy\",feature_2)\n",
        "    np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/test_3_RAFDB2_v1.npy\",feature_3)\n",
        "    np.save(\"/content/drive/MyDrive/FER/Orthognal_npy/test_label_RAFDB2_v1.npy\",label)\n"
      ],
      "metadata": {
        "id": "YNTnrMj6hru2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "BhQaqLAeg_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q-vit_RAFDB_Upload**"
      ],
      "metadata": {
        "id": "Hi74EF8ylgur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/FER/complexnn.zip"
      ],
      "metadata": {
        "id": "rCFZJdpNwFBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wsgiref import validate\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "BKcl998flmlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "metadata": {
        "id": "rWr8K7ITmKPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import os"
      ],
      "metadata": {
        "id": "oTEWIYm1lsjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.compat.v1.Session(config=config)"
      ],
      "metadata": {
        "id": "erOuOZqLnJh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "ro9TeNg-nTcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load orthogonal features\n",
        "train_1=np.load('/content/drive/MyDrive/FER/Orthognal_npy/train_1_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "train_2=np.load('/content/drive/MyDrive/FER/Orthognal_npy/train_2_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "train_3=np.load('/content/drive/MyDrive/FER/Orthognal_npy/train_3_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "train_label=np.load('/content/drive/MyDrive/FER/Orthognal_npy/train_label_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "test_1=np.load('/content/drive/MyDrive/FER/Orthognal_npy/test_1_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "test_2=np.load('/content/drive/MyDrive/FER/Orthognal_npy/test_2_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "test_3=np.load('/content/drive/MyDrive/FER/Orthognal_npy/test_3_RAFDB2_v1.npy',encoding = \"latin1\")\n",
        "test_label=np.load('/content/drive/MyDrive/FER/Orthognal_npy/test_label_RAFDB2_v1.npy',encoding = \"latin1\")"
      ],
      "metadata": {
        "id": "Ht1ShW_gnWfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average the three sub-features and put them into a quaternion matrix\n",
        "q_train=np.zeros([train_1.shape[0],train_1.shape[1],train_1.shape[2],train_1.shape[-1]*4])\n",
        "train_r=(train_1+train_2+train_3)/3\n",
        "q_train[:,:,:,:train_1.shape[-1]]=train_r\n",
        "q_train[:,:,:,train_1.shape[-1]:2*train_1.shape[-1]]=train_1\n",
        "q_train[:,:,:,2*train_1.shape[-1]:3*train_1.shape[-1]]=train_2\n",
        "q_train[:,:,:,3*train_1.shape[-1]:]=train_3\n",
        "train = np.transpose(q_train,(0,3,1,2))\n",
        "train = np.reshape(train,(train_1.shape[0],64*4,49))  # 256 --> 64\n",
        "\n",
        "q_test=np.zeros([test_1.shape[0],test_1.shape[1],test_1.shape[2],test_1.shape[-1]*4])\n",
        "test_r=(test_1+test_2+test_3)/3\n",
        "q_test[:,:,:,:test_1.shape[-1]]=test_r\n",
        "q_test[:,:,:,test_1.shape[-1]:2*test_1.shape[-1]]=test_1\n",
        "q_test[:,:,:,2*test_1.shape[-1]:3*test_1.shape[-1]]=test_2\n",
        "q_test[:,:,:,3*test_1.shape[-1]:]=test_3\n",
        "test = np.transpose(q_test,(0,3,1,2))\n",
        "test = np.reshape(test,(test_1.shape[0],64*4,49)) # 256 --> 64\n",
        "\n",
        "\n",
        "input_shape = (64*4, 49) # 256 --> 64\n",
        "num_classes = 7\n",
        "learning_rate = 0.00001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 8\n",
        "num_epochs = 100  # 400 >>> 100\n",
        "num_patches = 64*4  # 256 --> 64\n",
        "projection_dim = 48\n",
        "num_heads = 8\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]\n",
        "transformer_layers = 4\n",
        "mlp_head_units = [2048, 256]  # 1024 --> 256\n",
        "\n",
        "## go complexnn/init.py and change the \"from keras.utils.generic_utils.....\" to\n",
        "## \"from tensorflow.keras.utils import (serialize_keras_object, deserialize_keras_object)\"\n",
        "from   complexnn      import *\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        ")"
      ],
      "metadata": {
        "id": "9JYGgkg-sq7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-MHSA module\n",
        "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = QuaternionDense(embed_dim)\n",
        "        self.key_dense = QuaternionDense(embed_dim)\n",
        "        self.value_dense = QuaternionDense(embed_dim)\n",
        "        self.combine_heads = QuaternionDense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(\n",
        "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
        "        )\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        query = self.separate_heads(query, batch_size)\n",
        "        key = self.separate_heads(key, batch_size)\n",
        "        value = self.separate_heads(value, batch_size)\n",
        "\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output"
      ],
      "metadata": {
        "id": "g0ROyhZswSz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def QF_Net(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = QuaternionConv2D(int(units/4), 3, strides=1, padding=\"same\")(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x = layers.Activation(tf.nn.gelu)(x)\n",
        "        x = QuaternionConv2D(int(units/4), 3, strides=1, padding=\"same\")(x)\n",
        "    return x\n",
        "\n",
        "def multilayer_perceptron(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = QuaternionDense(units, activation='relu')(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        # é™ä¸ºå…¨è¿žæŽ¥\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        # encoded = patch + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "\n",
        "def create_qvit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # position embedding\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(inputs)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "\n",
        "        attention_output = MultiHeadSelfAttention(projection_dim, num_heads)(x1)\n",
        "\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "\n",
        "        x4 = tf.keras.layers.Reshape((16,16,48))(x3) # 32*32 --> 16*16\n",
        "\n",
        "        x5 = QF_Net(x4, hidden_units=transformer_units, dropout_rate=0.3)\n",
        "\n",
        "        x6 = tf.keras.layers.Reshape((64*4, 48))(x5) #256-->64\n",
        "\n",
        "        encoded_patches = layers.Add()([x6, x2])\n",
        "\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "\n",
        "    features = multilayer_perceptron(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = tf.optimizers.Adam(\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"./tmp/RAFDB/model_{epoch:03d}-{val_accuracy:.4f}.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=train,\n",
        "        y=train_label,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=(test, test_label),\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "v_LFR15gz4hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_classifier = create_qvit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ],
      "metadata": {
        "id": "7xJRn5GD03aM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}